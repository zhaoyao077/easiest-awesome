{
  "url": "https://api.github.com/repos/apache/spark/issues/40389",
  "repository_url": "https://api.github.com/repos/apache/spark",
  "labels_url": "https://api.github.com/repos/apache/spark/issues/40389/labels{/name}",
  "comments_url": "https://api.github.com/repos/apache/spark/issues/40389/comments",
  "events_url": "https://api.github.com/repos/apache/spark/issues/40389/events",
  "html_url": "https://github.com/apache/spark/pull/40389",
  "id": 1620718346,
  "node_id": "PR_kwDOAQXtWs5L2oWS",
  "number": 40389,
  "title": "[SPARK-42767][CONNECT][TESTS] Add a precondition to start connect server fallback with `in-memory` and auto ignored some tests strongly depend on hive",
  "user": {
    "login": "LuciferYang",
    "id": 1475305,
    "node_id": "MDQ6VXNlcjE0NzUzMDU=",
    "avatar_url": "https://avatars.githubusercontent.com/u/1475305?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/LuciferYang",
    "html_url": "https://github.com/LuciferYang",
    "followers_url": "https://api.github.com/users/LuciferYang/followers",
    "following_url": "https://api.github.com/users/LuciferYang/following{/other_user}",
    "gists_url": "https://api.github.com/users/LuciferYang/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/LuciferYang/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/LuciferYang/subscriptions",
    "organizations_url": "https://api.github.com/users/LuciferYang/orgs",
    "repos_url": "https://api.github.com/users/LuciferYang/repos",
    "events_url": "https://api.github.com/users/LuciferYang/events{/privacy}",
    "received_events_url": "https://api.github.com/users/LuciferYang/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [
    {
      "id": 1405794576,
      "node_id": "MDU6TGFiZWwxNDA1Nzk0NTc2",
      "url": "https://api.github.com/repos/apache/spark/labels/SQL",
      "name": "SQL",
      "color": "ededed",
      "default": false,
      "description": null
    },
    {
      "id": 4556440342,
      "node_id": "LA_kwDOAQXtWs8AAAABD5XDFg",
      "url": "https://api.github.com/repos/apache/spark/labels/CONNECT",
      "name": "CONNECT",
      "color": "ededed",
      "default": false,
      "description": null
    }
  ],
  "state": "closed",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 10,
  "created_at": "2023-03-13T04:08:28Z",
  "updated_at": "2023-03-17T02:20:13Z",
  "closed_at": "2023-03-16T04:04:30Z",
  "author_association": "CONTRIBUTOR",
  "active_lock_reason": null,
  "draft": false,
  "pull_request": {
    "url": "https://api.github.com/repos/apache/spark/pulls/40389",
    "html_url": "https://github.com/apache/spark/pull/40389",
    "diff_url": "https://github.com/apache/spark/pull/40389.diff",
    "patch_url": "https://github.com/apache/spark/pull/40389.patch",
    "merged_at": null
  },
  "body": "### What changes were proposed in this pull request?\r\nThis pr adds a precondition before `RemoteSparkSession` starts connect server to check whether `spark-hive-**.jar` exists in the `assembly/target/scala-*/jars` directory, and will fallback to using `spark.sql.catalogImplementation=in-memory` to start the connect server if `spark-hive-**.jar` doesn't exist. \r\n\r\nWhen using `spark.sql.catalogImplementation=in-memory` to start connect server, some test cases that strongly rely on the hive module will be ignored rather than fail rudely.  At the same time, developers can see the following message on the terminal:\r\n\r\n```\r\n[info] ClientE2ETestSuite:\r\nWill start Spark Connect server with `spark.sql.catalogImplementation=in-memory`, some tests that rely on Hive will be ignored. If you don't want to skip them:\r\n1. Test with maven: run `build/mvn install -DskipTests -Phive` before testing\r\n2. Test with sbt: run test with `-Phive` profile\r\n```\r\n\r\n\r\n### Why are the changes needed?\r\nAvoid rough failure of connect client module UTs due to lack of hive-related dependency.\r\n\r\n\r\n### Does this PR introduce _any_ user-facing change?\r\nNo, just for test\r\n\r\n\r\n### How was this patch tested?\r\n- Manual  checked test with `-Phive` is same as before\r\n- Manual test:\r\n  - Maven\r\n\r\nrun \r\n```\r\nbuild/mvn clean install -DskipTests\r\nbuild/mvn test -pl connector/connect/client/jvm \r\n```\r\n\r\n**Before**\r\n\r\n```\r\nRun completed in 14 seconds, 999 milliseconds.\r\nTotal number of tests run: 684\r\nSuites: completed 12, aborted 0\r\nTests: succeeded 678, failed 6, canceled 0, ignored 1, pending 0\r\n*** 6 TESTS FAILED ***\r\n```\r\n\r\n**After**\r\n\r\n```\r\nDiscovery starting.\r\nDiscovery completed in 761 milliseconds.\r\nRun starting. Expected test count is: 684\r\nClientE2ETestSuite:\r\nWill start Spark Connect server with `spark.sql.catalogImplementation=in-memory`, some tests that rely on Hive will be ignored. If you don't want to skip them:\r\n1. Test with maven: run `build/mvn install -DskipTests -Phive` before testing\r\n2. Test with sbt: run test with `-Phive` profile\r\n...\r\nRun completed in 15 seconds, 994 milliseconds.\r\nTotal number of tests run: 682\r\nSuites: completed 12, aborted 0\r\nTests: succeeded 682, failed 0, canceled 2, ignored 1, pending 0\r\nAll tests passed.\r\n```\r\n\r\n  - SBT  \r\n \r\nrun `build/sbt clean \"connect-client-jvm/test\"`\r\n\r\n**Before**\r\n\r\n```\r\n[info] ClientE2ETestSuite:\r\n[info] org.apache.spark.sql.ClientE2ETestSuite *** ABORTED *** (1 minute, 3 seconds)\r\n[info]   java.lang.RuntimeException: Failed to start the test server on port 15960.\r\n[info]   at org.apache.spark.sql.connect.client.util.RemoteSparkSession.beforeAll(RemoteSparkSession.scala:129)\r\n[info]   at org.apache.spark.sql.connect.client.util.RemoteSparkSession.beforeAll$(RemoteSparkSession.scala:120)\r\n[info]   at org.apache.spark.sql.ClientE2ETestSuite.beforeAll(ClientE2ETestSuite.scala:37)\r\n[info]   at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:212)\r\n[info]   at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210)\r\n[info]   at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208)\r\n[info]   at org.apache.spark.sql.ClientE2ETestSuite.run(ClientE2ETestSuite.scala:37)\r\n[info]   at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:321)\r\n[info]   at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:517)\r\n[info]   at sbt.ForkMain$Run.lambda$runTest$1(ForkMain.java:413)\r\n[info]   at java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n[info]   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n[info]   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n[info]   at java.lang.Thread.run(Thread.java:750)\r\n\r\n```\r\n\r\n**After**\r\n\r\n```\r\n[info] ClientE2ETestSuite:\r\nWill start Spark Connect server with `spark.sql.catalogImplementation=in-memory`, some tests that rely on Hive will be ignored. If you don't want to skip them:\r\n1. Test with maven: run `build/mvn install -DskipTests -Phive` before testing\r\n2. Test with sbt: run test with `-Phive` profile\r\n....\r\n[info] Run completed in 22 seconds, 44 milliseconds.\r\n[info] Total number of tests run: 682\r\n[info] Suites: completed 11, aborted 0\r\n[info] Tests: succeeded 682, failed 0, canceled 2, ignored 1, pending 0\r\n[info] All tests passed.\r\n```",
  "closed_by": {
    "login": "HyukjinKwon",
    "id": 6477701,
    "node_id": "MDQ6VXNlcjY0Nzc3MDE=",
    "avatar_url": "https://avatars.githubusercontent.com/u/6477701?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/HyukjinKwon",
    "html_url": "https://github.com/HyukjinKwon",
    "followers_url": "https://api.github.com/users/HyukjinKwon/followers",
    "following_url": "https://api.github.com/users/HyukjinKwon/following{/other_user}",
    "gists_url": "https://api.github.com/users/HyukjinKwon/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/HyukjinKwon/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/HyukjinKwon/subscriptions",
    "organizations_url": "https://api.github.com/users/HyukjinKwon/orgs",
    "repos_url": "https://api.github.com/users/HyukjinKwon/repos",
    "events_url": "https://api.github.com/users/HyukjinKwon/events{/privacy}",
    "received_events_url": "https://api.github.com/users/HyukjinKwon/received_events",
    "type": "User",
    "site_admin": false
  },
  "reactions": {
    "url": "https://api.github.com/repos/apache/spark/issues/40389/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/apache/spark/issues/40389/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
