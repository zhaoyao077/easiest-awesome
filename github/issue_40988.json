{
  "url": "https://api.github.com/repos/apache/spark/issues/40988",
  "repository_url": "https://api.github.com/repos/apache/spark",
  "labels_url": "https://api.github.com/repos/apache/spark/issues/40988/labels{/name}",
  "comments_url": "https://api.github.com/repos/apache/spark/issues/40988/comments",
  "events_url": "https://api.github.com/repos/apache/spark/issues/40988/events",
  "html_url": "https://github.com/apache/spark/pull/40988",
  "id": 1687816158,
  "node_id": "PR_kwDOAQXtWs5PWQiT",
  "number": 40988,
  "title": "[SPARK-41971][SQL][PYTHON] Add a config for pandas conversion how to handle struct types",
  "user": {
    "login": "ueshin",
    "id": 506656,
    "node_id": "MDQ6VXNlcjUwNjY1Ng==",
    "avatar_url": "https://avatars.githubusercontent.com/u/506656?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/ueshin",
    "html_url": "https://github.com/ueshin",
    "followers_url": "https://api.github.com/users/ueshin/followers",
    "following_url": "https://api.github.com/users/ueshin/following{/other_user}",
    "gists_url": "https://api.github.com/users/ueshin/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/ueshin/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/ueshin/subscriptions",
    "organizations_url": "https://api.github.com/users/ueshin/orgs",
    "repos_url": "https://api.github.com/users/ueshin/repos",
    "events_url": "https://api.github.com/users/ueshin/events{/privacy}",
    "received_events_url": "https://api.github.com/users/ueshin/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [
    {
      "id": 1405794576,
      "node_id": "MDU6TGFiZWwxNDA1Nzk0NTc2",
      "url": "https://api.github.com/repos/apache/spark/labels/SQL",
      "name": "SQL",
      "color": "ededed",
      "default": false,
      "description": null
    },
    {
      "id": 1981527456,
      "node_id": "MDU6TGFiZWwxOTgxNTI3NDU2",
      "url": "https://api.github.com/repos/apache/spark/labels/CORE",
      "name": "CORE",
      "color": "ededed",
      "default": false,
      "description": null
    },
    {
      "id": 1982260031,
      "node_id": "MDU6TGFiZWwxOTgyMjYwMDMx",
      "url": "https://api.github.com/repos/apache/spark/labels/PYTHON",
      "name": "PYTHON",
      "color": "ededed",
      "default": false,
      "description": null
    },
    {
      "id": 1984361638,
      "node_id": "MDU6TGFiZWwxOTg0MzYxNjM4",
      "url": "https://api.github.com/repos/apache/spark/labels/R",
      "name": "R",
      "color": "ededed",
      "default": false,
      "description": null
    },
    {
      "id": 4556440342,
      "node_id": "LA_kwDOAQXtWs8AAAABD5XDFg",
      "url": "https://api.github.com/repos/apache/spark/labels/CONNECT",
      "name": "CONNECT",
      "color": "ededed",
      "default": false,
      "description": null
    }
  ],
  "state": "closed",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 2,
  "created_at": "2023-04-28T02:53:44Z",
  "updated_at": "2023-05-04T18:04:25Z",
  "closed_at": "2023-05-04T18:01:39Z",
  "author_association": "MEMBER",
  "active_lock_reason": null,
  "draft": false,
  "pull_request": {
    "url": "https://api.github.com/repos/apache/spark/pulls/40988",
    "html_url": "https://github.com/apache/spark/pull/40988",
    "diff_url": "https://github.com/apache/spark/pull/40988.diff",
    "patch_url": "https://github.com/apache/spark/pull/40988.patch",
    "merged_at": null
  },
  "body": "### What changes were proposed in this pull request?\r\n\r\nAdds a config for pandas conversion how to handle struct types.\r\n\r\n- `spark.sql.execution.pandas.structHandlingMode` (default: `\"legacy\"`)\r\n\r\nThe conversion mode of struct type when creating pandas DataFrame.\r\n\r\n#### When `\"legacy\"`, the behavior is the same as before, except that with Arrow and Spark Connect will raise a more readable exception when there are duplicated nested field names.\r\n\r\n```py\r\n>>> spark.sql(\"values (1, struct(1 as a, 2 as a)) as t(x, y)\").toPandas()\r\nTraceback (most recent call last):\r\n...\r\npyspark.errors.exceptions.connect.UnsupportedOperationException: [DUPLICATED_FIELD_NAME_IN_ARROW_STRUCT] Duplicated field names in Arrow Struct are not allowed, got [a, a].\r\n```\r\n\r\n#### When `\"row\"`, convert to Row object regardless of Arrow optimization.\r\n\r\n```py\r\n>>> spark.conf.set('spark.sql.execution.pandas.structHandlingMode', 'row')\r\n>>> spark.conf.set('spark.sql.execution.arrow.pyspark.enabled', False)\r\n>>> spark.sql(\"values (1, struct(1 as a, 2 as b)) as t(x, y)\").toPandas()\r\n   x       y\r\n0  1  (1, 2)\r\n>>> spark.sql(\"values (1, struct(1 as a, 2 as a)) as t(x, y)\").toPandas()\r\n   x       y\r\n0  1  (1, 2)\r\n>>> spark.conf.set('spark.sql.execution.arrow.pyspark.enabled', True)\r\n>>> spark.sql(\"values (1, struct(1 as a, 2 as b)) as t(x, y)\").toPandas()\r\n   x       y\r\n0  1  (1, 2)\r\n>>> spark.sql(\"values (1, struct(1 as a, 2 as a)) as t(x, y)\").toPandas()\r\n   x       y\r\n0  1  (1, 2)\r\n```\r\n\r\n#### When `\"dict\"`, convert to dict and use suffixed key names, e.g., `a_0`, `a_1`, if there are duplicated nested field names, regardless of Arrow optimization.\r\n\r\n```py\r\n>>> spark.conf.set('spark.sql.execution.pandas.structHandlingMode', 'dict')\r\n>>> spark.conf.set('spark.sql.execution.arrow.pyspark.enabled', False)\r\n>>> spark.sql(\"values (1, struct(1 as a, 2 as b)) as t(x, y)\").toPandas()\r\n   x                 y\r\n0  1  {'a': 1, 'b': 2}\r\n>>> spark.sql(\"values (1, struct(1 as a, 2 as a)) as t(x, y)\").toPandas()\r\n   x                     y\r\n0  1  {'a_0': 1, 'a_1': 2}\r\n>>> spark.conf.set('spark.sql.execution.arrow.pyspark.enabled', True)\r\n>>> spark.sql(\"values (1, struct(1 as a, 2 as b)) as t(x, y)\").toPandas()\r\n   x                 y\r\n0  1  {'a': 1, 'b': 2}\r\n>>> spark.sql(\"values (1, struct(1 as a, 2 as a)) as t(x, y)\").toPandas()\r\n   x                     y\r\n0  1  {'a_0': 1, 'a_1': 2}\r\n```\r\n\r\n### Why are the changes needed?\r\n\r\nCurrently there are three behaviors when `df.toPandas()` with nested struct types:\r\n\r\n- vanilla PySpark with Arrow optimization disabled\r\n\r\n```py\r\n>>> spark.conf.set('spark.sql.execution.arrow.pyspark.enabled', False)\r\n>>> spark.sql(\"values (1, struct(1 as a, 2 as b)) as t(x, y)\").toPandas()\r\n   x       y\r\n0  1  (1, 2)\r\n```\r\n\r\nusing `Row` object for struct types.\r\n\r\nIt can use duplicated field names.\r\n\r\n```py\r\n>>> spark.sql(\"values (1, struct(1 as a, 2 as a)) as t(x, y)\").toPandas()\r\n   x       y\r\n0  1  (1, 2)\r\n```\r\n\r\n- vanilla PySpark with Arrow optimization enabled\r\n\r\n```py\r\n>>> spark.conf.set('spark.sql.execution.arrow.pyspark.enabled', True)\r\n>>> spark.sql(\"values (1, struct(1 as a, 2 as b)) as t(x, y)\").toPandas()\r\n   x                 y\r\n0  1  {'a': 1, 'b': 2}\r\n```\r\n\r\nusing `dict` for struct types.\r\n\r\nIt raises an Exception when there are duplicated nested field names:\r\n\r\n```py\r\n>>> spark.sql(\"values (1, struct(1 as a, 2 as a)) as t(x, y)\").toPandas()\r\nTraceback (most recent call last):\r\n...\r\npyarrow.lib.ArrowInvalid: Ran out of field metadata, likely malformed\r\n```\r\n\r\n- Spark Connect\r\n\r\n```py\r\n>>> spark.sql(\"values (1, struct(1 as a, 2 as b)) as t(x, y)\").toPandas()\r\n   x                 y\r\n0  1  {'a': 1, 'b': 2}\r\n```\r\n\r\nusing `dict` for struct types.\r\n\r\nIf there are duplicated nested field names, the duplicated keys are suffixed:\r\n\r\n```py\r\n>>> spark.sql(\"values (1, struct(1 as a, 2 as a)) as t(x, y)\").toPandas()\r\n   x                     y\r\n0  1  {'a_0': 1, 'a_1': 2}\r\n```\r\n\r\n### Does this PR introduce _any_ user-facing change?\r\n\r\nUsers will be able to configure the behavior.\r\n\r\n### How was this patch tested?\r\n\r\nModified the related tests.",
  "closed_by": {
    "login": "xinrong-meng",
    "id": 47337188,
    "node_id": "MDQ6VXNlcjQ3MzM3MTg4",
    "avatar_url": "https://avatars.githubusercontent.com/u/47337188?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/xinrong-meng",
    "html_url": "https://github.com/xinrong-meng",
    "followers_url": "https://api.github.com/users/xinrong-meng/followers",
    "following_url": "https://api.github.com/users/xinrong-meng/following{/other_user}",
    "gists_url": "https://api.github.com/users/xinrong-meng/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/xinrong-meng/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/xinrong-meng/subscriptions",
    "organizations_url": "https://api.github.com/users/xinrong-meng/orgs",
    "repos_url": "https://api.github.com/users/xinrong-meng/repos",
    "events_url": "https://api.github.com/users/xinrong-meng/events{/privacy}",
    "received_events_url": "https://api.github.com/users/xinrong-meng/received_events",
    "type": "User",
    "site_admin": false
  },
  "reactions": {
    "url": "https://api.github.com/repos/apache/spark/issues/40988/reactions",
    "total_count": 1,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 1,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/apache/spark/issues/40988/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
