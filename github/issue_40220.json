{
  "url": "https://api.github.com/repos/apache/spark/issues/40220",
  "repository_url": "https://api.github.com/repos/apache/spark",
  "labels_url": "https://api.github.com/repos/apache/spark/issues/40220/labels{/name}",
  "comments_url": "https://api.github.com/repos/apache/spark/issues/40220/comments",
  "events_url": "https://api.github.com/repos/apache/spark/issues/40220/events",
  "html_url": "https://github.com/apache/spark/pull/40220",
  "id": 1603370289,
  "node_id": "PR_kwDOAQXtWs5K8mrI",
  "number": 40220,
  "title": "[SPARK-42647][PYTHON] Change alias for numpy deprecated and removed types",
  "user": {
    "login": "aimtsou",
    "id": 2598924,
    "node_id": "MDQ6VXNlcjI1OTg5MjQ=",
    "avatar_url": "https://avatars.githubusercontent.com/u/2598924?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/aimtsou",
    "html_url": "https://github.com/aimtsou",
    "followers_url": "https://api.github.com/users/aimtsou/followers",
    "following_url": "https://api.github.com/users/aimtsou/following{/other_user}",
    "gists_url": "https://api.github.com/users/aimtsou/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/aimtsou/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/aimtsou/subscriptions",
    "organizations_url": "https://api.github.com/users/aimtsou/orgs",
    "repos_url": "https://api.github.com/users/aimtsou/repos",
    "events_url": "https://api.github.com/users/aimtsou/events{/privacy}",
    "received_events_url": "https://api.github.com/users/aimtsou/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [
    {
      "id": 1405794576,
      "node_id": "MDU6TGFiZWwxNDA1Nzk0NTc2",
      "url": "https://api.github.com/repos/apache/spark/labels/SQL",
      "name": "SQL",
      "color": "ededed",
      "default": false,
      "description": null
    },
    {
      "id": 1981527456,
      "node_id": "MDU6TGFiZWwxOTgxNTI3NDU2",
      "url": "https://api.github.com/repos/apache/spark/labels/CORE",
      "name": "CORE",
      "color": "ededed",
      "default": false,
      "description": null
    },
    {
      "id": 1982260031,
      "node_id": "MDU6TGFiZWwxOTgyMjYwMDMx",
      "url": "https://api.github.com/repos/apache/spark/labels/PYTHON",
      "name": "PYTHON",
      "color": "ededed",
      "default": false,
      "description": null
    },
    {
      "id": 4138679613,
      "node_id": "LA_kwDOAQXtWs72rz09",
      "url": "https://api.github.com/repos/apache/spark/labels/PANDAS%20API%20ON%20SPARK",
      "name": "PANDAS API ON SPARK",
      "color": "ededed",
      "default": false,
      "description": null
    }
  ],
  "state": "closed",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 20,
  "created_at": "2023-02-28T16:12:05Z",
  "updated_at": "2023-03-03T00:51:31Z",
  "closed_at": "2023-03-03T00:50:28Z",
  "author_association": "CONTRIBUTOR",
  "active_lock_reason": null,
  "draft": false,
  "pull_request": {
    "url": "https://api.github.com/repos/apache/spark/pulls/40220",
    "html_url": "https://github.com/apache/spark/pull/40220",
    "diff_url": "https://github.com/apache/spark/pull/40220.diff",
    "patch_url": "https://github.com/apache/spark/pull/40220.patch",
    "merged_at": null
  },
  "body": "### Problem description\r\nNumpy has started changing the alias to some of its data-types. This means that users with the latest version of numpy they will face either warnings or errors according to the type that they are using. This affects all the users using numoy > 1.20.0\r\nOne of the types was fixed back in September with this [pull](https://github.com/apache/spark/pull/37817) request\r\n\r\n[numpy 1.24.0](https://github.com/numpy/numpy/pull/22607): The scalar type aliases ending in a 0 bit size: np.object0, np.str0, np.bytes0, np.void0, np.int0, np.uint0 as well as np.bool8 are now deprecated and will eventually be removed.\r\n[numpy 1.20.0](https://github.com/numpy/numpy/pull/14882): Using the aliases of builtin types like np.int is deprecated\r\n\r\n### What changes were proposed in this pull request?\r\nFrom numpy 1.20.0 we receive a deprecattion warning on np.object(https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations) and from numpy 1.24.0 we received an attribute error:\r\n\r\n```\r\nattr = 'object'\r\n\r\n    def __getattr__(attr):\r\n        # Warn for expired attributes, and return a dummy function\r\n        # that always raises an exception.\r\n        import warnings\r\n        try:\r\n            msg = __expired_functions__[attr]\r\n        except KeyError:\r\n            pass\r\n        else:\r\n            warnings.warn(msg, DeprecationWarning, stacklevel=2)\r\n    \r\n            def _expired(*args, **kwds):\r\n                raise RuntimeError(msg)\r\n    \r\n            return _expired\r\n    \r\n        # Emit warnings for deprecated attributes\r\n        try:\r\n            val, msg = __deprecated_attrs__[attr]\r\n        except KeyError:\r\n            pass\r\n        else:\r\n            warnings.warn(msg, DeprecationWarning, stacklevel=2)\r\n            return val\r\n    \r\n        if attr in __future_scalars__:\r\n            # And future warnings for those that will change, but also give\r\n            # the AttributeError\r\n            warnings.warn(\r\n                f\"In the future `np.{attr}` will be defined as the \"\r\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\r\n    \r\n        if attr in __former_attrs__:\r\n>           raise AttributeError(__former_attrs__[attr])\r\nE           AttributeError: module 'numpy' has no attribute 'object'.\r\nE           `np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe. \r\nE           The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\r\nE               https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n```\r\n\r\nFrom numpy version 1.24.0 we receive a deprecation warning on np.object0 and every np.datatype0 and np.bool8\r\n>>> np.object0(123)\r\n<stdin>:1: DeprecationWarning: `np.object0` is a deprecated alias for ``np.object0` is a deprecated alias for `np.object_`. `object` can be used instead.  (Deprecated NumPy 1.24)`.  (Deprecated NumPy 1.24)\r\n\r\n### Why are the changes needed?\r\nThe changes are needed so pyspark can be compatible with the latest numpy and avoid \r\n\r\n- attribute errors on data types being deprecated from version 1.20.0: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n- warnings on deprecated data types from version 1.24.0: https://numpy.org/devdocs/release/1.24.0-notes.html#deprecations\r\n\r\n\r\n### Does this PR introduce _any_ user-facing change?\r\nThe change will suppress the warning coming from numpy 1.24.0 and the error coming from numpy 1.22.0\r\n\r\n### How was this patch tested?\r\nI assume that the existing tests should catch this. (see all section Extra questions)\r\n\r\nI found this to be a problem in my work's project where we use for our unit tests the toPandas() function to convert to np.object. Attaching the run result of our test:\r\n\r\n```\r\n\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n/usr/local/lib/python3.9/dist-packages/<my-pkg>/unit/spark_test.py:64: in run_testcase\r\n    self.handler.compare_df(result, expected, config=self.compare_config)\r\n/usr/local/lib/python3.9/dist-packages/<my-pkg>/spark_test_handler.py:38: in compare_df\r\n    actual_pd = actual.toPandas().sort_values(by=sort_columns, ignore_index=True)\r\n/usr/local/lib/python3.9/dist-packages/pyspark/sql/pandas/conversion.py:232: in toPandas\r\n    corrected_dtypes[index] = np.object  # type: ignore[attr-defined]\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nattr = 'object'\r\n\r\n    def __getattr__(attr):\r\n        # Warn for expired attributes, and return a dummy function\r\n        # that always raises an exception.\r\n        import warnings\r\n        try:\r\n            msg = __expired_functions__[attr]\r\n        except KeyError:\r\n            pass\r\n        else:\r\n            warnings.warn(msg, DeprecationWarning, stacklevel=2)\r\n    \r\n            def _expired(*args, **kwds):\r\n                raise RuntimeError(msg)\r\n    \r\n            return _expired\r\n    \r\n        # Emit warnings for deprecated attributes\r\n        try:\r\n            val, msg = __deprecated_attrs__[attr]\r\n        except KeyError:\r\n            pass\r\n        else:\r\n            warnings.warn(msg, DeprecationWarning, stacklevel=2)\r\n            return val\r\n    \r\n        if attr in __future_scalars__:\r\n            # And future warnings for those that will change, but also give\r\n            # the AttributeError\r\n            warnings.warn(\r\n                f\"In the future `np.{attr}` will be defined as the \"\r\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\r\n    \r\n        if attr in __former_attrs__:\r\n>           raise AttributeError(__former_attrs__[attr])\r\nE           AttributeError: module 'numpy' has no attribute 'object'.\r\nE           `np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe. \r\nE           The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\r\nE               https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n\r\n/usr/local/lib/python3.9/dist-packages/numpy/__init__.py:305: AttributeError\r\n```\r\n\r\nAlthough i cannot provide the code doing in python the following should show the problem:\r\n```\r\n>>> import numpy as np\r\n>>> np.object0(123)\r\n<stdin>:1: DeprecationWarning: `np.object0` is a deprecated alias for ``np.object0` is a deprecated alias for `np.object_`. `object` can be used instead.  (Deprecated NumPy 1.24)`.  (Deprecated NumPy 1.24)\r\n123\r\n>>> np.object(123)\r\n<stdin>:1: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python3.9/dist-packages/numpy/__init__.py\", line 305, in __getattr__\r\n    raise AttributeError(__former_attrs__[attr])\r\nAttributeError: module 'numpy' has no attribute 'object'.\r\n`np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe. \r\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\r\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\r\n```\r\n\r\nI do not have a use-case in my tests for np.object0 but I fixed like the suggestion from numpy\r\n\r\n### Supported Versions:\r\nI propose this fix to be included in all pyspark 3.3 and onwards\r\n\r\n### JIRA\r\nI know a JIRA ticket should be created I sent an email and I am waiting for the answer to document the case also there.\r\n\r\n### Extra questions:\r\nBy grepping for np.bool and np.object I see that the tests include them. Shall we change them also? Data types with _ I think they are not affected.\r\n\r\n```\r\ngit grep np.object\r\npython/pyspark/ml/functions.py:        return data.dtype == np.object_ and isinstance(data.iloc[0], (np.ndarray, list))\r\npython/pyspark/ml/functions.py:        return any(data.dtypes == np.object_) and any(\r\npython/pyspark/sql/tests/test_dataframe.py:        self.assertEqual(types[1], np.object)\r\npython/pyspark/sql/tests/test_dataframe.py:        self.assertEqual(types[4], np.object)  # datetime.date\r\npython/pyspark/sql/tests/test_dataframe.py:        self.assertEqual(types[1], np.object)\r\npython/pyspark/sql/tests/test_dataframe.py:                self.assertEqual(types[6], np.object)\r\npython/pyspark/sql/tests/test_dataframe.py:                self.assertEqual(types[7], np.object)\r\n\r\ngit grep np.bool\r\npython/docs/source/user_guide/pandas_on_spark/types.rst:np.bool       BooleanType\r\npython/pyspark/pandas/indexing.py:            isinstance(key, np.bool_) for key in cols_sel\r\npython/pyspark/pandas/tests/test_typedef.py:            np.bool: (np.bool, BooleanType()),\r\npython/pyspark/pandas/tests/test_typedef.py:            bool: (np.bool, BooleanType()),\r\npython/pyspark/pandas/typedef/typehints.py:    elif tpe in (bool, np.bool_, \"bool\", \"?\"):\r\npython/pyspark/sql/connect/expressions.py:                assert isinstance(value, (bool, np.bool_))\r\npython/pyspark/sql/connect/expressions.py:                elif isinstance(value, np.bool_):\r\npython/pyspark/sql/tests/test_dataframe.py:        self.assertEqual(types[2], np.bool)\r\npython/pyspark/sql/tests/test_functions.py:            (np.bool_, [(\"true\", \"boolean\")]),\r\n```\r\n\r\nIf yes concerning bool was merged already should we fix it too?",
  "closed_by": {
    "login": "srowen",
    "id": 822522,
    "node_id": "MDQ6VXNlcjgyMjUyMg==",
    "avatar_url": "https://avatars.githubusercontent.com/u/822522?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/srowen",
    "html_url": "https://github.com/srowen",
    "followers_url": "https://api.github.com/users/srowen/followers",
    "following_url": "https://api.github.com/users/srowen/following{/other_user}",
    "gists_url": "https://api.github.com/users/srowen/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/srowen/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/srowen/subscriptions",
    "organizations_url": "https://api.github.com/users/srowen/orgs",
    "repos_url": "https://api.github.com/users/srowen/repos",
    "events_url": "https://api.github.com/users/srowen/events{/privacy}",
    "received_events_url": "https://api.github.com/users/srowen/received_events",
    "type": "User",
    "site_admin": false
  },
  "reactions": {
    "url": "https://api.github.com/repos/apache/spark/issues/40220/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/apache/spark/issues/40220/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
