{
  "url": "https://api.github.com/repos/apache/spark/issues/40015",
  "repository_url": "https://api.github.com/repos/apache/spark",
  "labels_url": "https://api.github.com/repos/apache/spark/issues/40015/labels{/name}",
  "comments_url": "https://api.github.com/repos/apache/spark/issues/40015/comments",
  "events_url": "https://api.github.com/repos/apache/spark/issues/40015/events",
  "html_url": "https://github.com/apache/spark/pull/40015",
  "id": 1584216917,
  "node_id": "PR_kwDOAQXtWs5J8pXS",
  "number": 40015,
  "title": "[SPARK-42437][PYTHON][CONNECT] PySpark catalog.cacheTable will allow to specify storage level",
  "user": {
    "login": "khalidmammadov",
    "id": 11574708,
    "node_id": "MDQ6VXNlcjExNTc0NzA4",
    "avatar_url": "https://avatars.githubusercontent.com/u/11574708?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/khalidmammadov",
    "html_url": "https://github.com/khalidmammadov",
    "followers_url": "https://api.github.com/users/khalidmammadov/followers",
    "following_url": "https://api.github.com/users/khalidmammadov/following{/other_user}",
    "gists_url": "https://api.github.com/users/khalidmammadov/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/khalidmammadov/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/khalidmammadov/subscriptions",
    "organizations_url": "https://api.github.com/users/khalidmammadov/orgs",
    "repos_url": "https://api.github.com/users/khalidmammadov/repos",
    "events_url": "https://api.github.com/users/khalidmammadov/events{/privacy}",
    "received_events_url": "https://api.github.com/users/khalidmammadov/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [
    {
      "id": 1405794576,
      "node_id": "MDU6TGFiZWwxNDA1Nzk0NTc2",
      "url": "https://api.github.com/repos/apache/spark/labels/SQL",
      "name": "SQL",
      "color": "ededed",
      "default": false,
      "description": null
    },
    {
      "id": 1981527456,
      "node_id": "MDU6TGFiZWwxOTgxNTI3NDU2",
      "url": "https://api.github.com/repos/apache/spark/labels/CORE",
      "name": "CORE",
      "color": "ededed",
      "default": false,
      "description": null
    },
    {
      "id": 1982260031,
      "node_id": "MDU6TGFiZWwxOTgyMjYwMDMx",
      "url": "https://api.github.com/repos/apache/spark/labels/PYTHON",
      "name": "PYTHON",
      "color": "ededed",
      "default": false,
      "description": null
    },
    {
      "id": 4556440342,
      "node_id": "LA_kwDOAQXtWs8AAAABD5XDFg",
      "url": "https://api.github.com/repos/apache/spark/labels/CONNECT",
      "name": "CONNECT",
      "color": "ededed",
      "default": false,
      "description": null
    }
  ],
  "state": "closed",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 11,
  "created_at": "2023-02-14T13:59:50Z",
  "updated_at": "2023-04-12T20:37:23Z",
  "closed_at": "2023-04-12T20:12:06Z",
  "author_association": "CONTRIBUTOR",
  "active_lock_reason": null,
  "draft": false,
  "pull_request": {
    "url": "https://api.github.com/repos/apache/spark/pulls/40015",
    "html_url": "https://github.com/apache/spark/pull/40015",
    "diff_url": "https://github.com/apache/spark/pull/40015.diff",
    "patch_url": "https://github.com/apache/spark/pull/40015.patch",
    "merged_at": null
  },
  "body": "Currently PySpark version of `catalog.cacheTable` function does not support to specify storage level. This is to add that.\r\n\r\nAfter changes:\r\n\r\n## Spark Connect\r\n\r\n```\r\nbin/pyspark --remote \"local[*]\"\r\nPython 3.9.5 (default, Nov 23 2021, 15:27:38) \r\n[GCC 9.3.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\nSetting default log level to \"WARN\".\r\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\r\n23/02/17 20:41:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\r\nWelcome to\r\n\r\n      ____              __\r\n     / __/__  ___ _____/ /__\r\n    _\\ \\/ _ \\/ _ `/ __/  '_/\r\n   /__ / .__/\\_,_/_/ /_/\\_\\   version 3.5.0.dev0\r\n      /_/\r\n\r\nUsing Python version 3.9.5 (default, Nov 23 2021 15:27:38)\r\nClient connected to the Spark Connect server at localhost\r\nSparkSession available as 'spark'.\r\n>>> spark.range(1).write.saveAsTable(\"tab1\", format=\"csv\", mode=\"overwrite\")\r\n>>> spark.catalog.listTables()\r\n[Table(name='tab1', catalog='spark_catalog', namespace=['default'], description=None, tableType='MANAGED', isTemporary=False)]\r\n>>> spark.catalog.cacheTable(\"tab1\")\r\n>>> spark.catalog.isCached(\"tab1\")\r\nTrue\r\n>>> spark.catalog.clearCache()\r\n>>> spark.catalog.isCached(\"tab1\")\r\nFalse\r\n>>> from pyspark.storagelevel import StorageLevel\r\n>>> spark.catalog.cacheTable(\"tab1\", StorageLevel.OFF_HEAP)\r\n>>> spark.catalog.isCached(\"tab1\")\r\nTrue\r\n```\r\n\r\n## PySpark\r\n```\r\n/home/spark# bin/pyspark\r\nPython 3.9.5 (default, Nov 23 2021, 15:27:38) \r\n[GCC 9.3.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\nSetting default log level to \"WARN\".\r\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\r\n23/02/17 20:43:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\r\nWelcome to\r\n      ____              __\r\n     / __/__  ___ _____/ /__\r\n    _\\ \\/ _ \\/ _ `/ __/  '_/\r\n   /__ / .__/\\_,_/_/ /_/\\_\\   version 3.5.0-SNAPSHOT\r\n      /_/\r\n\r\nUsing Python version 3.9.5 (default, Nov 23 2021 15:27:38)\r\nSpark context Web UI available at http://localhost:4040\r\nSpark context available as 'sc' (master = local[*], app id = local-1676666626670).\r\nSparkSession available as 'spark'.\r\n\r\n>>> spark.range(1).write.saveAsTable(\"tab2\", format=\"csv\", mode=\"overwrite\")\r\n>>> spark.catalog.listTables()\r\n[Table(name='tab2', catalog='spark_catalog', namespace=['default'], description=None, tableType='MANAGED', isTemporary=False)]\r\n>>> spark.catalog.cacheTable(\"tab2\")\r\n>>> \r\n>>> spark.catalog.isCached(\"tab2\")\r\nTrue\r\n>>> spark.catalog.clearCache()\r\n>>> spark.catalog.isCached(\"tab2\")\r\nFalse\r\n>>> from pyspark.storagelevel import StorageLevel\r\n>>> spark.catalog.cacheTable(\"tab2\", StorageLevel.OFF_HEAP)\r\n>>> spark.catalog.isCached(\"tab2\")\r\nTrue\r\n\r\n```\r\n\r\n\r\n### What changes were proposed in this pull request?\r\nAdd extra parameter to catalog.cacheTable\r\n\r\n\r\n### Why are the changes needed?\r\nTo allow users specify which storage level to use in cache in PySpark/Connect code\r\n\r\n\r\n### Does this PR introduce _any_ user-facing change?\r\nYes\r\n\r\n### How was this patch tested?\r\nUpdated existing test cases \r\n",
  "closed_by": {
    "login": "ueshin",
    "id": 506656,
    "node_id": "MDQ6VXNlcjUwNjY1Ng==",
    "avatar_url": "https://avatars.githubusercontent.com/u/506656?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/ueshin",
    "html_url": "https://github.com/ueshin",
    "followers_url": "https://api.github.com/users/ueshin/followers",
    "following_url": "https://api.github.com/users/ueshin/following{/other_user}",
    "gists_url": "https://api.github.com/users/ueshin/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/ueshin/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/ueshin/subscriptions",
    "organizations_url": "https://api.github.com/users/ueshin/orgs",
    "repos_url": "https://api.github.com/users/ueshin/repos",
    "events_url": "https://api.github.com/users/ueshin/events{/privacy}",
    "received_events_url": "https://api.github.com/users/ueshin/received_events",
    "type": "User",
    "site_admin": false
  },
  "reactions": {
    "url": "https://api.github.com/repos/apache/spark/issues/40015/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/apache/spark/issues/40015/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
