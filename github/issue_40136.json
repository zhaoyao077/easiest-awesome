{
  "url": "https://api.github.com/repos/apache/spark/issues/40136",
  "repository_url": "https://api.github.com/repos/apache/spark",
  "labels_url": "https://api.github.com/repos/apache/spark/issues/40136/labels{/name}",
  "comments_url": "https://api.github.com/repos/apache/spark/issues/40136/comments",
  "events_url": "https://api.github.com/repos/apache/spark/issues/40136/events",
  "html_url": "https://github.com/apache/spark/pull/40136",
  "id": 1596150072,
  "node_id": "PR_kwDOAQXtWs5KkZ1L",
  "number": 40136,
  "title": "[SPARK-42515][BUILD][CONNECT][TESTS] Make `write table` in `ClientE2ETestSuite` sbt local test pass",
  "user": {
    "login": "LuciferYang",
    "id": 1475305,
    "node_id": "MDQ6VXNlcjE0NzUzMDU=",
    "avatar_url": "https://avatars.githubusercontent.com/u/1475305?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/LuciferYang",
    "html_url": "https://github.com/LuciferYang",
    "followers_url": "https://api.github.com/users/LuciferYang/followers",
    "following_url": "https://api.github.com/users/LuciferYang/following{/other_user}",
    "gists_url": "https://api.github.com/users/LuciferYang/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/LuciferYang/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/LuciferYang/subscriptions",
    "organizations_url": "https://api.github.com/users/LuciferYang/orgs",
    "repos_url": "https://api.github.com/users/LuciferYang/repos",
    "events_url": "https://api.github.com/users/LuciferYang/events{/privacy}",
    "received_events_url": "https://api.github.com/users/LuciferYang/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [
    {
      "id": 1406627200,
      "node_id": "MDU6TGFiZWwxNDA2NjI3MjAw",
      "url": "https://api.github.com/repos/apache/spark/labels/BUILD",
      "name": "BUILD",
      "color": "ededed",
      "default": false,
      "description": null
    }
  ],
  "state": "closed",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 6,
  "created_at": "2023-02-23T03:19:25Z",
  "updated_at": "2023-02-28T04:03:27Z",
  "closed_at": "2023-02-28T03:58:33Z",
  "author_association": "CONTRIBUTOR",
  "active_lock_reason": null,
  "draft": false,
  "pull_request": {
    "url": "https://api.github.com/repos/apache/spark/pulls/40136",
    "html_url": "https://github.com/apache/spark/pull/40136",
    "diff_url": "https://github.com/apache/spark/pull/40136.diff",
    "patch_url": "https://github.com/apache/spark/pull/40136.patch",
    "merged_at": null
  },
  "body": "### What changes were proposed in this pull request?\r\nThis pr use `LocalProject(\"assembly\") / Compile / Keys.package` instead of `buildTestDeps` to ensure `${SPARK_HOME}/assembly/target/scala-$SPARK_SCALA_VERSION/jars` is available for testing for `connect-client-jvm` module.\r\n\r\nOn the other hand, this pr also add similar options support for `testOnly`\r\n\r\n\r\n\r\n\r\n### Why are the changes needed?\r\nMake `write table` in `ClientE2ETestSuite` sbt local test pass \r\n\r\n\r\n### Does this PR introduce _any_ user-facing change?\r\nNo\r\n\r\n\r\n### How was this patch tested?\r\n\r\n- Pass GitHub Actions\r\n- Manual testï¼š\r\n\r\nrun `test`\r\n\r\n```\r\nbuild/sbt clean \"connect-client-jvm/test\"\r\n```\r\n\r\n**Before**\r\n\r\n```\r\n[info] - write table *** FAILED *** (34 milliseconds)\r\n[info]   io.grpc.StatusRuntimeException: UNKNOWN: org/apache/parquet/hadoop/api/ReadSupport\r\n[info]   at io.grpc.Status.asRuntimeException(Status.java:535)\r\n[info]   at io.grpc.stub.ClientCalls$BlockingResponseStream.hasNext(ClientCalls.java:660)\r\n[info]   at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:45)\r\n[info]   at scala.collection.Iterator.foreach(Iterator.scala:943)\r\n[info]   at scala.collection.Iterator.foreach$(Iterator.scala:943)\r\n[info]   at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\r\n[info]   at org.apache.spark.sql.SparkSession.execute(SparkSession.scala:169)\r\n[info]   at org.apache.spark.sql.DataFrameWriter.executeWriteOperation(DataFrameWriter.scala:255)\r\n[info]   at org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:338)\r\n[info]   at org.apache.spark.sql.ClientE2ETestSuite.$anonfun$new$13(ClientE2ETestSuite.scala:145)\r\n[info]   at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n[info]   at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1520)\r\n[info]   at org.apache.spark.sql.connect.client.util.RemoteSparkSession.withTable(RemoteSparkSession.scala:169)\r\n[info]   at org.apache.spark.sql.connect.client.util.RemoteSparkSession.withTable$(RemoteSparkSession.scala:167)\r\n[info]   at org.apache.spark.sql.ClientE2ETestSuite.withTable(ClientE2ETestSuite.scala:33)\r\n[info]   at org.apache.spark.sql.ClientE2ETestSuite.$anonfun$new$12(ClientE2ETestSuite.scala:143)\r\n[info]   at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n[info]   at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)\r\n[info]   at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)\r\n[info]   at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)\r\n[info]   at org.scalatest.Transformer.apply(Transformer.scala:22)\r\n[info]   at org.scalatest.Transformer.apply(Transformer.scala:20)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike$$anon$1.apply(AnyFunSuiteLike.scala:226)\r\n[info]   at org.scalatest.TestSuite.withFixture(TestSuite.scala:196)\r\n[info]   at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)\r\n[info]   at org.scalatest.funsuite.AnyFunSuite.withFixture(AnyFunSuite.scala:1564)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.invokeWithFixture$1(AnyFunSuiteLike.scala:224)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTest$1(AnyFunSuiteLike.scala:236)\r\n[info]   at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.runTest(AnyFunSuiteLike.scala:236)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.runTest$(AnyFunSuiteLike.scala:218)\r\n[info]   at org.scalatest.funsuite.AnyFunSuite.runTest(AnyFunSuite.scala:1564)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTests$1(AnyFunSuiteLike.scala:269)\r\n[info]   at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)\r\n[info]   at scala.collection.immutable.List.foreach(List.scala:431)\r\n[info]   at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\r\n[info]   at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)\r\n[info]   at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.runTests(AnyFunSuiteLike.scala:269)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.runTests$(AnyFunSuiteLike.scala:268)\r\n[info]   at org.scalatest.funsuite.AnyFunSuite.runTests(AnyFunSuite.scala:1564)\r\n[info]   at org.scalatest.Suite.run(Suite.scala:1114)\r\n[info]   at org.scalatest.Suite.run$(Suite.scala:1096)\r\n[info]   at org.scalatest.funsuite.AnyFunSuite.org$scalatest$funsuite$AnyFunSuiteLike$$super$run(AnyFunSuite.scala:1564)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$run$1(AnyFunSuiteLike.scala:273)\r\n[info]   at org.scalatest.SuperEngine.runImpl(Engine.scala:535)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.run(AnyFunSuiteLike.scala:273)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.run$(AnyFunSuiteLike.scala:272)\r\n[info]   at org.apache.spark.sql.ClientE2ETestSuite.org$scalatest$BeforeAndAfterAll$$super$run(ClientE2ETestSuite.scala:33)\r\n[info]   at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213)\r\n[info]   at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210)\r\n[info]   at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208)\r\n[info]   at org.apache.spark.sql.ClientE2ETestSuite.run(ClientE2ETestSuite.scala:33)\r\n[info]   at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:321)\r\n[info]   at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:517)\r\n[info]   at sbt.ForkMain$Run.lambda$runTest$1(ForkMain.java:413)\r\n[info]   at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\r\n[info]   at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n[info]   at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n[info]   at java.base/java.lang.Thread.run(Thread.java:833)\r\nWarning: Unable to serialize throwable of type io.grpc.StatusRuntimeException for TestFailed(Ordinal(0, 15),UNKNOWN: org/apache/parquet/hadoop/api/ReadSupport,ClientE2ETestSuite,org.apache.spark.sql.ClientE2ETestSuite,Some(org.apache.spark.sql.ClientE2ETestSuite),write table,write table,Vector(),Vector(),Some(io.grpc.StatusRuntimeException: UNKNOWN: org/apache/parquet/hadoop/api/ReadSupport),Some(34),Some(IndentedText(- write table,write table,0)),Some(SeeStackDepthException),Some(org.apache.spark.sql.ClientE2ETestSuite),None,pool-1-thread-1-ScalaTest-running-ClientE2ETestSuite,1677123932064), setting it as NotSerializableWrapperException.\r\nWarning: Unable to read from client, please check on client for futher details of the problem.\r\n[info] - writeTo with create and using *** FAILED *** (27 milliseconds)\r\n[info]   io.grpc.StatusRuntimeException: UNKNOWN: org/apache/parquet/hadoop/api/ReadSupport\r\n[info]   at io.grpc.Status.asRuntimeException(Status.java:535)\r\n[info]   at io.grpc.stub.ClientCalls$BlockingResponseStream.hasNext(ClientCalls.java:660)\r\n[info]   at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:45)\r\n[info]   at scala.collection.Iterator.foreach(Iterator.scala:943)\r\n[info]   at scala.collection.Iterator.foreach$(Iterator.scala:943)\r\n[info]   at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\r\n[info]   at org.apache.spark.sql.SparkSession.execute(SparkSession.scala:169)\r\n[info]   at org.apache.spark.sql.DataFrameWriterV2.executeWriteOperation(DataFrameWriterV2.scala:160)\r\n[info]   at org.apache.spark.sql.DataFrameWriterV2.create(DataFrameWriterV2.scala:81)\r\n[info]   at org.apache.spark.sql.ClientE2ETestSuite.$anonfun$new$15(ClientE2ETestSuite.scala:162)\r\n[info]   at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n[info]   at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1520)\r\n[info]   at org.apache.spark.sql.connect.client.util.RemoteSparkSession.withTable(RemoteSparkSession.scala:169)\r\n[info]   at org.apache.spark.sql.connect.client.util.RemoteSparkSession.withTable$(RemoteSparkSession.scala:167)\r\n[info]   at org.apache.spark.sql.ClientE2ETestSuite.withTable(ClientE2ETestSuite.scala:33)\r\n[info]   at org.apache.spark.sql.ClientE2ETestSuite.$anonfun$new$14(ClientE2ETestSuite.scala:161)\r\n[info]   at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n[info]   at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)\r\n[info]   at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)\r\n[info]   at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)\r\n[info]   at org.scalatest.Transformer.apply(Transformer.scala:22)\r\n[info]   at org.scalatest.Transformer.apply(Transformer.scala:20)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike$$anon$1.apply(AnyFunSuiteLike.scala:226)\r\n[info]   at org.scalatest.TestSuite.withFixture(TestSuite.scala:196)\r\n[info]   at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)\r\n[info]   at org.scalatest.funsuite.AnyFunSuite.withFixture(AnyFunSuite.scala:1564)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.invokeWithFixture$1(AnyFunSuiteLike.scala:224)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTest$1(AnyFunSuiteLike.scala:236)\r\n[info]   at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.runTest(AnyFunSuiteLike.scala:236)\r\nWarning: Unable to serialize throwable of type io.grpc.StatusRuntimeException for TestFailed(Ordinal(0, 17),UNKNOWN: org/apache/parquet/hadoop/api/ReadSupport,ClientE2ETestSuite,org.apache.spark.sql.ClientE2ETestSuite,Some(org.apache.spark.sql.ClientE2ETestSuite),writeTo with create and using,writeTo with create and using,Vector(),Vector(),Some(io.grpc.StatusRuntimeException: UNKNOWN: org/apache/parquet/hadoop/api/ReadSupport),Some(27),Some(IndentedText(- writeTo with create and using,writeTo with create and using,0)),Some(SeeStackDepthException),Some(org.apache.spark.sql.ClientE2ETestSuite),None,pool-1-thread-1-ScalaTest-running-ClientE2ETestSuite,1677123932096), setting it as NotSerializableWrapperException.\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.runTest$(AnyFunSuiteLike.scala:218)\r\n[info]   at org.scalatest.funsuite.AnyFunSuite.runTest(AnyFunSuite.scala:1564)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTests$1(AnyFunSuiteLike.scala:269)\r\n[info]   at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)\r\n[info]   at scala.collection.immutable.List.foreach(List.scala:431)\r\n[info]   at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\r\n[info]   at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)\r\n[info]   at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.runTests(AnyFunSuiteLike.scala:269)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.runTests$(AnyFunSuiteLike.scala:268)\r\n[info]   at org.scalatest.funsuite.AnyFunSuite.runTests(AnyFunSuite.scala:1564)\r\n[info]   at org.scalatest.Suite.run(Suite.scala:1114)\r\n[info]   at org.scalatest.Suite.run$(Suite.scala:1096)\r\n[info]   at org.scalatest.funsuite.AnyFunSuite.org$scalatest$funsuite$AnyFunSuiteLike$$super$run(AnyFunSuite.scala:1564)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$run$1(AnyFunSuiteLike.scala:273)\r\n[info]   at org.scalatest.SuperEngine.runImpl(Engine.scala:535)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.run(AnyFunSuiteLike.scala:273)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.run$(AnyFunSuiteLike.scala:272)\r\n[info]   at org.apache.spark.sql.ClientE2ETestSuite.org$scalatest$BeforeAndAfterAll$$super$run(ClientE2ETestSuite.scala:33)\r\n[info]   at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213)\r\nWarning: Unable to read from client, please check on client for futher details of the problem.\r\n[info]   at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210)\r\n[info]   at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208)\r\n[info]   at org.apache.spark.sql.ClientE2ETestSuite.run(ClientE2ETestSuite.scala:33)\r\n[info]   at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:321)\r\n[info]   at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:517)\r\n[info]   at sbt.ForkMain$Run.lambda$runTest$1(ForkMain.java:413)\r\n[info]   at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\r\n[info]   at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n[info]   at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n[info]   at java.base/java.lang.Thread.run(Thread.java:833)\r\n[info] - writeTo with create and append *** FAILED *** (20 milliseconds)\r\n[info]   io.grpc.StatusRuntimeException: UNKNOWN: org/apache/parquet/hadoop/api/ReadSupport\r\n[info]   at io.grpc.Status.asRuntimeException(Status.java:535)\r\n[info]   at io.grpc.stub.ClientCalls$BlockingResponseStream.hasNext(ClientCalls.java:660)\r\n[info]   at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:45)\r\n[info]   at scala.collection.Iterator.foreach(Iterator.scala:943)\r\n[info]   at scala.collection.Iterator.foreach$(Iterator.scala:943)\r\n[info]   at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\r\n[info]   at org.apache.spark.sql.SparkSession.execute(SparkSession.scala:169)\r\n[info]   at org.apache.spark.sql.DataFrameWriterV2.executeWriteOperation(DataFrameWriterV2.scala:160)\r\n[info]   at org.apache.spark.sql.DataFrameWriterV2.create(DataFrameWriterV2.scala:81)\r\n[info]   at org.apache.spark.sql.ClientE2ETestSuite.$anonfun$new$17(ClientE2ETestSuite.scala:175)\r\n[info]   at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n[info]   at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1520)\r\n[info]   at org.apache.spark.sql.connect.client.util.RemoteSparkSession.withTable(RemoteSparkSession.scala:169)\r\n[info]   at org.apache.spark.sql.connect.client.util.RemoteSparkSession.withTable$(RemoteSparkSession.scala:167)\r\n[info]   at org.apache.spark.sql.ClientE2ETestSuite.withTable(ClientE2ETestSuite.scala:33)\r\n[info]   at org.apache.spark.sql.ClientE2ETestSuite.$anonfun$new$16(ClientE2ETestSuite.scala:174)\r\n[info]   at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n[info]   at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)\r\n[info]   at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)\r\n[info]   at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)\r\n[info]   at org.scalatest.Transformer.apply(Transformer.scala:22)\r\n[info]   at org.scalatest.Transformer.apply(Transformer.scala:20)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike$$anon$1.apply(AnyFunSuiteLike.scala:226)\r\n[info]   at org.scalatest.TestSuite.withFixture(TestSuite.scala:196)\r\n[info]   at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)\r\n[info]   at org.scalatest.funsuite.AnyFunSuite.withFixture(AnyFunSuite.scala:1564)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.invokeWithFixture$1(AnyFunSuiteLike.scala:224)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTest$1(AnyFunSuiteLike.scala:236)\r\n[info]   at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.runTest(AnyFunSuiteLike.scala:236)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.runTest$(AnyFunSuiteLike.scala:218)\r\n[info]   at org.scalatest.funsuite.AnyFunSuite.runTest(AnyFunSuite.scala:1564)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTests$1(AnyFunSuiteLike.scala:269)\r\n[info]   at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)\r\n[info]   at scala.collection.immutable.List.foreach(List.scala:431)\r\n[info]   at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\r\nWarning: Unable to read from client, please check on client for futher details of the problem.\r\n[info]   at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)\r\nWarning: Unable to serialize throwable of type io.grpc.StatusRuntimeException for TestFailed(Ordinal(0, 19),UNKNOWN: org/apache/parquet/hadoop/api/ReadSupport,ClientE2ETestSuite,org.apache.spark.sql.ClientE2ETestSuite,Some(org.apache.spark.sql.ClientE2ETestSuite),writeTo with create and append,writeTo with create and append,Vector(),Vector(),Some(io.grpc.StatusRuntimeException: UNKNOWN: org/apache/parquet/hadoop/api/ReadSupport),Some(20),Some(IndentedText(- writeTo with create and append,writeTo with create and append,0)),Some(SeeStackDepthException),Some(org.apache.spark.sql.ClientE2ETestSuite),None,pool-1-thread-1-ScalaTest-running-ClientE2ETestSuite,1677123932118), setting it as NotSerializableWrapperException.\r\n[info]   at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)\r\nFatal: Existing as unable to continue running tests, after 3 failing attempts to read event from server socket. [info]   at org.scalatest.funsuite.AnyFunSuiteLike.runTests(AnyFunSuiteLike.scala:269)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.runTests$(AnyFunSuiteLike.scala:268)\r\n[info]   at org.scalatest.funsuite.AnyFunSuite.runTests(AnyFunSuite.scala:1564)\r\n[info]   at org.scalatest.Suite.run(Suite.scala:1114)\r\n\r\n[info]   at org.scalatest.Suite.run$(Suite.scala:1096)\r\n[info]   at org.scalatest.funsuite.AnyFunSuite.org$scalatest$funsuite$AnyFunSuiteLike$$super$run(AnyFunSuite.scala:1564)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$run$1(AnyFunSuiteLike.scala:273)\r\n[info]   at org.scalatest.SuperEngine.runImpl(Engine.scala:535)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.run(AnyFunSuiteLike.scala:273)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.run$(AnyFunSuiteLike.scala:272)\r\n[info]   at org.apache.spark.sql.ClientE2ETestSuite.org$scalatest$BeforeAndAfterAll$$super$run(ClientE2ETestSuite.scala:33)\r\n[info]   at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213)\r\n[info]   at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210)\r\n[info]   at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208)\r\n[info]   at org.apache.spark.sql.ClientE2ETestSuite.run(ClientE2ETestSuite.scala:33)\r\n[info]   at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:321)\r\n[info]   at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:517)\r\n[info]   at sbt.ForkMain$Run.lambda$runTest$1(ForkMain.java:413)\r\n[info]   at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\r\n[info]   at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n[info]   at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n[info]   at java.base/java.lang.Thread.run(Thread.java:833)\r\n\r\n```\r\n\r\n**After**\r\n\r\n```\r\n[info] Run completed in 12 seconds, 629 milliseconds.\r\n[info] Total number of tests run: 505\r\n[info] Suites: completed 9, aborted 0\r\n[info] Tests: succeeded 505, failed 0, canceled 0, ignored 0, pending 0\r\n[info] All tests passed.\r\n```\r\n\r\nrun `testOnly`\r\n\r\n```\r\nbuild/sbt clean \"connect-client-jvm/testOnly *ClientE2ETestSuite\"\r\nbuild/sbt clean \"connect-client-jvm/testOnly *CompatibilitySuite\"   \r\n```\r\n\r\n**Before**\r\n\r\n```\r\n[info] org.apache.spark.sql.ClientE2ETestSuite *** ABORTED *** (27 milliseconds)\r\n[info]   java.lang.AssertionError: assertion failed: Failed to find the jar inside folder: /spark/connector/connect/server/target\r\n[info]   at scala.Predef$.assert(Predef.scala:223)\r\n[info]   at org.apache.spark.sql.connect.client.util.IntegrationTestUtils$.findJar(IntegrationTestUtils.scala:67)\r\n[info]   at org.apache.spark.sql.connect.client.util.SparkConnectServerUtils$.sparkConnect$lzycompute(RemoteSparkSession.scala:64)\r\n[info]   at org.apache.spark.sql.connect.client.util.SparkConnectServerUtils$.sparkConnect(RemoteSparkSession.scala:59)\r\n[info]   at org.apache.spark.sql.connect.client.util.SparkConnectServerUtils$.start(RemoteSparkSession.scala:90)\r\n[info]   at org.apache.spark.sql.connect.client.util.RemoteSparkSession.beforeAll(RemoteSparkSession.scala:120)\r\n[info]   at org.apache.spark.sql.connect.client.util.RemoteSparkSession.beforeAll$(RemoteSparkSession.scala:118)\r\n[info]   at org.apache.spark.sql.ClientE2ETestSuite.beforeAll(ClientE2ETestSuite.scala:33)\r\n[info]   at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:212)\r\n[info]   at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210)\r\n[info]   at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208)\r\n[info]   at org.apache.spark.sql.ClientE2ETestSuite.run(ClientE2ETestSuite.scala:33)\r\n[info]   at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:321)\r\n[info]   at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:517)\r\n[info]   at sbt.ForkMain$Run.lambda$runTest$1(ForkMain.java:413)\r\n[info]   at java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n[info]   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n[info]   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n[info]   at java.lang.Thread.run(Thread.java:750)\r\n\r\n[info] - compatibility MiMa tests *** FAILED *** (27 milliseconds)\r\n[info]   java.lang.AssertionError: assertion failed: Failed to find the jar inside folder: /spark/connector/connect/client/jvm/target\r\n[info]   at scala.Predef$.assert(Predef.scala:223)\r\n[info]   at org.apache.spark.sql.connect.client.util.IntegrationTestUtils$.findJar(IntegrationTestUtils.scala:67)\r\n[info]   at org.apache.spark.sql.connect.client.CompatibilitySuite.clientJar$lzycompute(CompatibilitySuite.scala:57)\r\n[info]   at org.apache.spark.sql.connect.client.CompatibilitySuite.clientJar(CompatibilitySuite.scala:53)\r\n[info]   at org.apache.spark.sql.connect.client.CompatibilitySuite.$anonfun$new$1(CompatibilitySuite.scala:69)\r\n[info]   at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)\r\n[info]   at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)\r\n[info]   at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)\r\n[info]   at org.scalatest.Transformer.apply(Transformer.scala:22)\r\n[info]   at org.scalatest.Transformer.apply(Transformer.scala:20)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike$$anon$1.apply(AnyFunSuiteLike.scala:226)\r\n[info]   at org.scalatest.TestSuite.withFixture(TestSuite.scala:196)\r\n[info]   at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195)\r\n[info]   at org.scalatest.funsuite.AnyFunSuite.withFixture(AnyFunSuite.scala:1564)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.invokeWithFixture$1(AnyFunSuiteLike.scala:224)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTest$1(AnyFunSuiteLike.scala:236)\r\n[info]   at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.runTest(AnyFunSuiteLike.scala:236)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.runTest$(AnyFunSuiteLike.scala:218)\r\n[info]   at org.scalatest.funsuite.AnyFunSuite.runTest(AnyFunSuite.scala:1564)\r\n\r\n```\r\n\r\n**After**\r\n\r\n```\r\n[info] Run completed in 13 seconds, 572 milliseconds.\r\n[info] Total number of tests run: 17\r\n[info] Suites: completed 1, aborted 0\r\n[info] Tests: succeeded 17, failed 0, canceled 0, ignored 0, pending 0\r\n[info] All tests passed\r\n\r\n[info] Run completed in 1 second, 578 milliseconds.\r\n[info] Total number of tests run: 2\r\n[info] Suites: completed 1, aborted 0\r\n[info] Tests: succeeded 2, failed 0, canceled 0, ignored 0, pending 0\r\n[info] All tests passed.\r\n```",
  "closed_by": {
    "login": "HyukjinKwon",
    "id": 6477701,
    "node_id": "MDQ6VXNlcjY0Nzc3MDE=",
    "avatar_url": "https://avatars.githubusercontent.com/u/6477701?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/HyukjinKwon",
    "html_url": "https://github.com/HyukjinKwon",
    "followers_url": "https://api.github.com/users/HyukjinKwon/followers",
    "following_url": "https://api.github.com/users/HyukjinKwon/following{/other_user}",
    "gists_url": "https://api.github.com/users/HyukjinKwon/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/HyukjinKwon/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/HyukjinKwon/subscriptions",
    "organizations_url": "https://api.github.com/users/HyukjinKwon/orgs",
    "repos_url": "https://api.github.com/users/HyukjinKwon/repos",
    "events_url": "https://api.github.com/users/HyukjinKwon/events{/privacy}",
    "received_events_url": "https://api.github.com/users/HyukjinKwon/received_events",
    "type": "User",
    "site_admin": false
  },
  "reactions": {
    "url": "https://api.github.com/repos/apache/spark/issues/40136/reactions",
    "total_count": 1,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 1,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/apache/spark/issues/40136/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
