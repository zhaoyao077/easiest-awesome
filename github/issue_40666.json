{
  "url": "https://api.github.com/repos/apache/spark/issues/40666",
  "repository_url": "https://api.github.com/repos/apache/spark",
  "labels_url": "https://api.github.com/repos/apache/spark/issues/40666/labels{/name}",
  "comments_url": "https://api.github.com/repos/apache/spark/issues/40666/comments",
  "events_url": "https://api.github.com/repos/apache/spark/issues/40666/events",
  "html_url": "https://github.com/apache/spark/pull/40666",
  "id": 1654288805,
  "node_id": "PR_kwDOAQXtWs5Nm1cr",
  "number": 40666,
  "title": "[SPARK-43009][SQL][3.4] Parameterized `sql()` with `Any` constants",
  "user": {
    "login": "MaxGekk",
    "id": 1580697,
    "node_id": "MDQ6VXNlcjE1ODA2OTc=",
    "avatar_url": "https://avatars.githubusercontent.com/u/1580697?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/MaxGekk",
    "html_url": "https://github.com/MaxGekk",
    "followers_url": "https://api.github.com/users/MaxGekk/followers",
    "following_url": "https://api.github.com/users/MaxGekk/following{/other_user}",
    "gists_url": "https://api.github.com/users/MaxGekk/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/MaxGekk/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/MaxGekk/subscriptions",
    "organizations_url": "https://api.github.com/users/MaxGekk/orgs",
    "repos_url": "https://api.github.com/users/MaxGekk/repos",
    "events_url": "https://api.github.com/users/MaxGekk/events{/privacy}",
    "received_events_url": "https://api.github.com/users/MaxGekk/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [
    {
      "id": 1405794576,
      "node_id": "MDU6TGFiZWwxNDA1Nzk0NTc2",
      "url": "https://api.github.com/repos/apache/spark/labels/SQL",
      "name": "SQL",
      "color": "ededed",
      "default": false,
      "description": null
    },
    {
      "id": 1981527456,
      "node_id": "MDU6TGFiZWwxOTgxNTI3NDU2",
      "url": "https://api.github.com/repos/apache/spark/labels/CORE",
      "name": "CORE",
      "color": "ededed",
      "default": false,
      "description": null
    },
    {
      "id": 1982260031,
      "node_id": "MDU6TGFiZWwxOTgyMjYwMDMx",
      "url": "https://api.github.com/repos/apache/spark/labels/PYTHON",
      "name": "PYTHON",
      "color": "ededed",
      "default": false,
      "description": null
    },
    {
      "id": 4556440342,
      "node_id": "LA_kwDOAQXtWs8AAAABD5XDFg",
      "url": "https://api.github.com/repos/apache/spark/labels/CONNECT",
      "name": "CONNECT",
      "color": "ededed",
      "default": false,
      "description": null
    }
  ],
  "state": "closed",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 1,
  "created_at": "2023-04-04T17:30:51Z",
  "updated_at": "2023-04-05T00:12:27Z",
  "closed_at": "2023-04-05T00:12:27Z",
  "author_association": "MEMBER",
  "active_lock_reason": null,
  "draft": false,
  "pull_request": {
    "url": "https://api.github.com/repos/apache/spark/pulls/40666",
    "html_url": "https://github.com/apache/spark/pull/40666",
    "diff_url": "https://github.com/apache/spark/pull/40666.diff",
    "patch_url": "https://github.com/apache/spark/pull/40666.patch",
    "merged_at": null
  },
  "body": "### What changes were proposed in this pull request?\r\nIn the PR, I propose to change API of parameterized SQL, and replace type of argument values from `string` to `Any` in Scala/Java/Python and `Expression.Literal` in protobuf API. Language API can accept `Any` objects from which it is possible to construct literal expressions.\r\n\r\nThis is a backport of https://github.com/apache/spark/pull/40623\r\n\r\n#### Scala/Java:\r\n\r\n```scala\r\n  def sql(sqlText: String, args: Map[String, Any]): DataFrame\r\n```\r\nvalues of the `args` map are wrapped by the `lit()` function which leaves `Column` as is and creates a literal from other Java/Scala objects (for more details see the `Scala` tab at https://spark.apache.org/docs/latest/sql-ref-datatypes.html).\r\n\r\n#### Python:\r\n\r\n```python\r\ndef sql(self, sqlQuery: str, args: Optional[Dict[str, Any]] = None, **kwargs: Any) -> DataFrame:\r\n```\r\nSimilarly to Scala/Java `sql`, Python's `sql()` accepts Python objects as values of the `args` dictionary (see more details about acceptable Python objects at https://spark.apache.org/docs/latest/sql-ref-datatypes.html). `sql()` converts dictionary values to `Column` literal expressions by `lit()`.\r\n\r\n#### Protobuf:\r\n\r\n```proto\r\nmessage SqlCommand {\r\n  // (Required) SQL Query.\r\n  string sql = 1;\r\n\r\n  // (Optional) A map of parameter names to literal expressions.\r\n  map<string, Expression.Literal> args = 2;\r\n}\r\n```\r\n\r\nFor example:\r\n```scala\r\nscala> val sqlText = \"\"\"SELECT s FROM VALUES ('Jeff /*__*/ Green'), ('E\\'Twaun Moore') AS t(s) WHERE s = :player_name\"\"\"\r\nsqlText: String = SELECT s FROM VALUES ('Jeff /*__*/ Green'), ('E\\'Twaun Moore') AS t(s) WHERE s = :player_name\r\n\r\nscala> sql(sqlText, args = Map(\"player_name\" -> lit(\"E'Twaun Moore\"))).show(false)\r\n+-------------+\r\n|s            |\r\n+-------------+\r\n|E'Twaun Moore|\r\n+-------------+\r\n```\r\n\r\n### Why are the changes needed?\r\nThe current implementation the parameterized `sql()` requires arguments as string values parsed to SQL literal expressions that causes the following issues:\r\n1. SQL comments are skipped while parsing, so, some fragments of input might be skipped. For example, `'Europe -- Amsterdam'`. In this case, `-- Amsterdam` is excluded from the input.\r\n2. Special chars in string values must be escaped, for instance `'E\\'Twaun Moore'`\r\n\r\n### Does this PR introduce _any_ user-facing change?\r\nNo since the parameterized SQL feature https://github.com/apache/spark/pull/38864 hasn't been released yet.\r\n\r\n### How was this patch tested?\r\nBy running the affected tests:\r\n```\r\n$ build/sbt \"test:testOnly *ParametersSuite\"\r\n$ python/run-tests --parallelism=1 --testnames 'pyspark.sql.tests.connect.test_connect_basic SparkConnectBasicTests.test_sql_with_args'\r\n$ python/run-tests --parallelism=1 --testnames 'pyspark.sql.session SparkSession.sql'\r\n```\r\n\r\nAuthored-by: Max Gekk <max.gekk@gmail.com>\r\n(cherry picked from commit 156a12ec0abba8362658a58e00179a0b80f663f2)",
  "closed_by": {
    "login": "HyukjinKwon",
    "id": 6477701,
    "node_id": "MDQ6VXNlcjY0Nzc3MDE=",
    "avatar_url": "https://avatars.githubusercontent.com/u/6477701?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/HyukjinKwon",
    "html_url": "https://github.com/HyukjinKwon",
    "followers_url": "https://api.github.com/users/HyukjinKwon/followers",
    "following_url": "https://api.github.com/users/HyukjinKwon/following{/other_user}",
    "gists_url": "https://api.github.com/users/HyukjinKwon/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/HyukjinKwon/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/HyukjinKwon/subscriptions",
    "organizations_url": "https://api.github.com/users/HyukjinKwon/orgs",
    "repos_url": "https://api.github.com/users/HyukjinKwon/repos",
    "events_url": "https://api.github.com/users/HyukjinKwon/events{/privacy}",
    "received_events_url": "https://api.github.com/users/HyukjinKwon/received_events",
    "type": "User",
    "site_admin": false
  },
  "reactions": {
    "url": "https://api.github.com/repos/apache/spark/issues/40666/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/apache/spark/issues/40666/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
