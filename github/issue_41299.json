{
  "url": "https://api.github.com/repos/apache/spark/issues/41299",
  "repository_url": "https://api.github.com/repos/apache/spark",
  "labels_url": "https://api.github.com/repos/apache/spark/issues/41299/labels{/name}",
  "comments_url": "https://api.github.com/repos/apache/spark/issues/41299/comments",
  "events_url": "https://api.github.com/repos/apache/spark/issues/41299/events",
  "html_url": "https://github.com/apache/spark/pull/41299",
  "id": 1724625597,
  "node_id": "PR_kwDOAQXtWs5RSCvW",
  "number": 41299,
  "title": "[DO NOT MERGE] scala Foreach test code",
  "user": {
    "login": "WweiL",
    "id": 10248890,
    "node_id": "MDQ6VXNlcjEwMjQ4ODkw",
    "avatar_url": "https://avatars.githubusercontent.com/u/10248890?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/WweiL",
    "html_url": "https://github.com/WweiL",
    "followers_url": "https://api.github.com/users/WweiL/followers",
    "following_url": "https://api.github.com/users/WweiL/following{/other_user}",
    "gists_url": "https://api.github.com/users/WweiL/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/WweiL/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/WweiL/subscriptions",
    "organizations_url": "https://api.github.com/users/WweiL/orgs",
    "repos_url": "https://api.github.com/users/WweiL/repos",
    "events_url": "https://api.github.com/users/WweiL/events{/privacy}",
    "received_events_url": "https://api.github.com/users/WweiL/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [
    {
      "id": 1405794576,
      "node_id": "MDU6TGFiZWwxNDA1Nzk0NTc2",
      "url": "https://api.github.com/repos/apache/spark/labels/SQL",
      "name": "SQL",
      "color": "ededed",
      "default": false,
      "description": null
    },
    {
      "id": 1406587328,
      "node_id": "MDU6TGFiZWwxNDA2NTg3MzI4",
      "url": "https://api.github.com/repos/apache/spark/labels/STRUCTURED%20STREAMING",
      "name": "STRUCTURED STREAMING",
      "color": "ededed",
      "default": false,
      "description": null
    },
    {
      "id": 1981527456,
      "node_id": "MDU6TGFiZWwxOTgxNTI3NDU2",
      "url": "https://api.github.com/repos/apache/spark/labels/CORE",
      "name": "CORE",
      "color": "ededed",
      "default": false,
      "description": null
    },
    {
      "id": 1982260031,
      "node_id": "MDU6TGFiZWwxOTgyMjYwMDMx",
      "url": "https://api.github.com/repos/apache/spark/labels/PYTHON",
      "name": "PYTHON",
      "color": "ededed",
      "default": false,
      "description": null
    },
    {
      "id": 4556440342,
      "node_id": "LA_kwDOAQXtWs8AAAABD5XDFg",
      "url": "https://api.github.com/repos/apache/spark/labels/CONNECT",
      "name": "CONNECT",
      "color": "ededed",
      "default": false,
      "description": null
    }
  ],
  "state": "closed",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 0,
  "created_at": "2023-05-24T19:40:13Z",
  "updated_at": "2023-05-25T17:53:33Z",
  "closed_at": "2023-05-25T17:27:15Z",
  "author_association": "CONTRIBUTOR",
  "active_lock_reason": null,
  "draft": true,
  "pull_request": {
    "url": "https://api.github.com/repos/apache/spark/pulls/41299",
    "html_url": "https://github.com/apache/spark/pull/41299",
    "diff_url": "https://github.com/apache/spark/pull/41299.diff",
    "patch_url": "https://github.com/apache/spark/pull/41299.patch",
    "merged_at": null
  },
  "body": "This PR tries to move `ForeachWriter` into the common folder but it doesn't work.\r\nConcretely:\r\n1. Move the original `ForeachWriter` from `org.spark.sql` to `org.spark.sql.utils`.\r\n2. Create a new `ForeachWriter` that extends that one. Because customer imports it from sql package\r\n3. Create a new `ForeachWriter` in common folder that extends the util one\r\n4. Create a new `ForeachWriter` in scala client side that extend the common one\r\n5. Cast the customer created `ForeachWriter`(client, package sql) to the one in common in `DataStreamWriter`\r\n6. Cast the proto to `ForeachWriter` in common in `SparkConnectPlanner`\r\n\r\n```\r\nimport org.apache.spark.sql.ForeachWriter\r\nimport java.io._ \r\n\r\nval filePath = \"/home/wei.liu/test_foreach/output-custom\" \r\n\r\ncase class MyTestClass(value: Int) {\r\n      override def toString: String = value.toString\r\n}\r\n\r\nval writer = new ForeachWriter[MyTestClass] {\r\n    var fileWriter: FileWriter = _\r\n\r\n    def open(partitionId: Long, version: Long): Boolean = {\r\n      fileWriter = new FileWriter(filePath, true)\r\n      true\r\n    }\r\n\r\n    def process(row: MyTestClass): Unit = {\r\n      fileWriter.write(row.toString)\r\n      fileWriter.write(\"\\n\")\r\n    }\r\n\r\n    def close(errorOrNull: Throwable): Unit = {\r\n      fileWriter.close()\r\n    }\r\n}\r\n\r\nval df = spark.readStream .format(\"rate\") .option(\"rowsPerSecond\", \"10\") .load()\r\nval query = df .selectExpr(\"CAST(value AS INT)\") .as[MyTestClass] .writeStream .foreach(writer) .outputMode(\"update\") .start()\r\n```\r\n\r\nError is:\r\n```\r\njava.lang.ClassCastException: ammonite.$sess.cmd5$Helper$$anon$1 cannot be cast to org.apache.spark.sql.connect.common.ForeachWriter\r\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.handleWriteStreamOperationStart(SparkConnectPlanner.scala:2472)\r\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.process(SparkConnectPlanner.scala:2112)\r\n\tat org.apache.spark.sql.connect.service.SparkConnectStreamHandler.handleCommand(SparkConnectStreamHandler.scala:120)\r\n\tat org.apache.spark.sql.connect.service.SparkConnectStreamHandler.$anonfun$handle$2(SparkConnectStreamHandler.scala:86)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:825)\r\n\tat org.apache.spark.sql.connect.service.SparkConnectStreamHandler.$anonfun$handle$1(SparkConnectStreamHandler.scala:53)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:209)\r\n\tat org.apache.spark.sql.connect.artifact.SparkConnectArtifactManager$.withArtifactClassLoader(SparkConnectArtifactManager.scala:193)\r\n\tat org.apache.spark.sql.connect.service.SparkConnectStreamHandler.handle(SparkConnectStreamHandler.scala:48)\r\n\tat org.apache.spark.sql.connect.service.SparkConnectService.executePlan(SparkConnectService.scala:166)\r\n\tat org.apache.spark.connect.proto.SparkConnectServiceGrpc$MethodHandlers.invoke(SparkConnectServiceGrpc.java:611)\r\n\tat org.sparkproject.connect.grpc.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)\r\n\tat org.sparkproject.connect.grpc.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:352)\r\n\tat org.sparkproject.connect.grpc.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:866)\r\n\tat org.sparkproject.connect.grpc.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)\r\n\tat org.sparkproject.connect.grpc.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n```\r\n\r\nThe hard requirement is the customer must be able to import a `ForeachWriter` in package `org.apache.spark.sql` and use it. \r\n",
  "closed_by": {
    "login": "WweiL",
    "id": 10248890,
    "node_id": "MDQ6VXNlcjEwMjQ4ODkw",
    "avatar_url": "https://avatars.githubusercontent.com/u/10248890?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/WweiL",
    "html_url": "https://github.com/WweiL",
    "followers_url": "https://api.github.com/users/WweiL/followers",
    "following_url": "https://api.github.com/users/WweiL/following{/other_user}",
    "gists_url": "https://api.github.com/users/WweiL/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/WweiL/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/WweiL/subscriptions",
    "organizations_url": "https://api.github.com/users/WweiL/orgs",
    "repos_url": "https://api.github.com/users/WweiL/repos",
    "events_url": "https://api.github.com/users/WweiL/events{/privacy}",
    "received_events_url": "https://api.github.com/users/WweiL/received_events",
    "type": "User",
    "site_admin": false
  },
  "reactions": {
    "url": "https://api.github.com/repos/apache/spark/issues/41299/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/apache/spark/issues/41299/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
