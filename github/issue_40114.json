{
  "url": "https://api.github.com/repos/apache/spark/issues/40114",
  "repository_url": "https://api.github.com/repos/apache/spark",
  "labels_url": "https://api.github.com/repos/apache/spark/issues/40114/labels{/name}",
  "comments_url": "https://api.github.com/repos/apache/spark/issues/40114/comments",
  "events_url": "https://api.github.com/repos/apache/spark/issues/40114/events",
  "html_url": "https://github.com/apache/spark/pull/40114",
  "id": 1594384511,
  "node_id": "PR_kwDOAQXtWs5Kefk6",
  "number": 40114,
  "title": "[SPARK-42513][SQL] Push down topK through join",
  "user": {
    "login": "wangyum",
    "id": 5399861,
    "node_id": "MDQ6VXNlcjUzOTk4NjE=",
    "avatar_url": "https://avatars.githubusercontent.com/u/5399861?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/wangyum",
    "html_url": "https://github.com/wangyum",
    "followers_url": "https://api.github.com/users/wangyum/followers",
    "following_url": "https://api.github.com/users/wangyum/following{/other_user}",
    "gists_url": "https://api.github.com/users/wangyum/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/wangyum/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/wangyum/subscriptions",
    "organizations_url": "https://api.github.com/users/wangyum/orgs",
    "repos_url": "https://api.github.com/users/wangyum/repos",
    "events_url": "https://api.github.com/users/wangyum/events{/privacy}",
    "received_events_url": "https://api.github.com/users/wangyum/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [
    {
      "id": 1405794576,
      "node_id": "MDU6TGFiZWwxNDA1Nzk0NTc2",
      "url": "https://api.github.com/repos/apache/spark/labels/SQL",
      "name": "SQL",
      "color": "ededed",
      "default": false,
      "description": null
    }
  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 3,
  "created_at": "2023-02-22T03:10:57Z",
  "updated_at": "2023-04-07T09:22:46Z",
  "closed_at": null,
  "author_association": "MEMBER",
  "active_lock_reason": null,
  "draft": false,
  "pull_request": {
    "url": "https://api.github.com/repos/apache/spark/pulls/40114",
    "html_url": "https://github.com/apache/spark/pull/40114",
    "diff_url": "https://github.com/apache/spark/pull/40114.diff",
    "patch_url": "https://github.com/apache/spark/pull/40114.patch",
    "merged_at": null
  },
  "body": "### What changes were proposed in this pull request?\r\n\r\nThis PR enhance `LimitPushDown` to support push down topK through join. The key idea is that if the order expressions comes from one join side and pushing down topK does not affect query result:\r\n1. Left outer join and order expressions come from the left side.\r\n2. Right outer join and order expressions come from the right side.\r\n3. Inner join, cross join, left outer join, right outer join, full outer join and join condition is empty and order expressions from one side.\r\n4. Left anti join, left semi join and join condition is empty and order expressions from left side.\r\n\r\n### Why are the changes needed?\r\n\r\nImprove query performance. [TiDB](https://docs.pingcap.com/tidb/dev/topn-limit-push-down) has this optimization.\r\n\r\nCase 1:\r\n```scala\r\nspark.range(100000000).selectExpr(\"id as a\", \"id as b\").write.saveAsTable(\"t1\")\r\nspark.range(100000000).selectExpr(\"id as x\", \"id as y\").write.saveAsTable(\"t2\")\r\n\r\nsql(\"select * from t1 left join t2 on a = x order by b limit 5\").collect()\r\nspark.sql(\"set spark.sql.optimizer.excludedRules=org.apache.spark.sql.catalyst.optimizer.LimitPushDown\")\r\nsql(\"select * from t1 left join t2 on a = x order by b limit 5\").collect()\r\n```\r\n\r\nDisable push down | Enable push down\r\n-- | --\r\n<img src=\"https://user-images.githubusercontent.com/5399861/220509675-b5bb96d2-c4cd-464f-b464-ff74c28a473c.png\" width=\"300\" height=\"630\"> | <img src=\"https://user-images.githubusercontent.com/5399861/220509756-66b1e981-25a9-4abd-8359-d0a8cb9924e9.png\" width=\"300\" height=\"630\">\r\n\r\n\r\nCase 2:\r\n```scala\r\nspark.range(100000000).selectExpr(\"id % 10000 as a\", \"id as b\").write.saveAsTable(\"t1\")\r\nspark.range(100000000).selectExpr(\"id % 10000 as x\", \"id as y\").write.saveAsTable(\"t2\")\r\n\r\nsql(\"select * from t1 left join t2 on a = x order by b limit 5\").collect()\r\nspark.sql(\"set spark.sql.optimizer.excludedRules=org.apache.spark.sql.catalyst.optimizer.LimitPushDown\")\r\nsql(\"select * from t1 left join t2 on a = x order by b limit 5\").collect()\r\n```\r\n\r\nDisable push down | Enable push down\r\n-- | --\r\n<img src=\"https://user-images.githubusercontent.com/5399861/220572967-53de205e-6a6e-4455-bded-a718659449df.png\" width=\"300\" height=\"630\"> | <img src=\"https://user-images.githubusercontent.com/5399861/220510582-f02045b1-93b8-4849-90a4-7c2ae42c765f.png\" width=\"300\" height=\"630\">\r\n\r\n### Does this PR introduce _any_ user-facing change?\r\n\r\nNo.\r\n\r\n### How was this patch tested?\r\n\r\nUnit test.",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/apache/spark/issues/40114/reactions",
    "total_count": 1,
    "+1": 1,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/apache/spark/issues/40114/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
