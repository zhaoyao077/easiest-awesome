{
  "url": "https://api.github.com/repos/apache/spark/issues/40812",
  "repository_url": "https://api.github.com/repos/apache/spark",
  "labels_url": "https://api.github.com/repos/apache/spark/issues/40812/labels{/name}",
  "comments_url": "https://api.github.com/repos/apache/spark/issues/40812/comments",
  "events_url": "https://api.github.com/repos/apache/spark/issues/40812/events",
  "html_url": "https://github.com/apache/spark/pull/40812",
  "id": 1670175953,
  "node_id": "PR_kwDOAQXtWs5ObMnN",
  "number": 40812,
  "title": "[SPARK-43157][SQL] Clone InMemoryRelation cached plan to prevent cloned plan from referencing same objects",
  "user": {
    "login": "robreeves",
    "id": 5604993,
    "node_id": "MDQ6VXNlcjU2MDQ5OTM=",
    "avatar_url": "https://avatars.githubusercontent.com/u/5604993?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/robreeves",
    "html_url": "https://github.com/robreeves",
    "followers_url": "https://api.github.com/users/robreeves/followers",
    "following_url": "https://api.github.com/users/robreeves/following{/other_user}",
    "gists_url": "https://api.github.com/users/robreeves/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/robreeves/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/robreeves/subscriptions",
    "organizations_url": "https://api.github.com/users/robreeves/orgs",
    "repos_url": "https://api.github.com/users/robreeves/repos",
    "events_url": "https://api.github.com/users/robreeves/events{/privacy}",
    "received_events_url": "https://api.github.com/users/robreeves/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [
    {
      "id": 1405794576,
      "node_id": "MDU6TGFiZWwxNDA1Nzk0NTc2",
      "url": "https://api.github.com/repos/apache/spark/labels/SQL",
      "name": "SQL",
      "color": "ededed",
      "default": false,
      "description": null
    }
  ],
  "state": "closed",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 7,
  "created_at": "2023-04-16T22:45:00Z",
  "updated_at": "2023-05-18T06:25:01Z",
  "closed_at": "2023-05-18T06:25:01Z",
  "author_association": "CONTRIBUTOR",
  "active_lock_reason": null,
  "draft": false,
  "pull_request": {
    "url": "https://api.github.com/repos/apache/spark/pulls/40812",
    "html_url": "https://github.com/apache/spark/pull/40812",
    "diff_url": "https://github.com/apache/spark/pull/40812.diff",
    "patch_url": "https://github.com/apache/spark/pull/40812.patch",
    "merged_at": null
  },
  "body": "### What changes were proposed in this pull request?\r\nThis is the most narrow fix for the issue observed in SPARK-43157. It does not attempt to identify or solve all potential correctness and concurrency issues from TreeNode.tags being modified in multiple places. It solves the issue described in  SPARK-43157 by cloning the cached plan when populating `InMemoryRelation.innerChildren`. I chose to do the clone at this point to limit the scope to tree traversal used for building up the string representation of the plan, which is where we see the issue. I do not see any other uses for `TreeNode.innerChildren`. I did not clone any earlier because the caching objects have mutable state that I wanted to avoid touching to be extra safe.\r\n\r\nAnother solution I tried was to modify `InMemoryRelation.clone` to create a new `CachedRDDBuilder` and pass in a cloned `cachedPlan`. I opted not to go with this approach because `CachedRDDBuilder` has mutable state that needs to be moved to the new object and I didn't want to add that complexity if not needed.\r\n\r\n### Why are the changes needed?\r\nWhen caching is used the cached part of the SparkPlan is leaked to new clones of the plan. This leakage is an issue because if the TreeNode.tags are modified in one plan, it impacts the other plan. This is a correctness issue and a concurrency issue if the TreeNode.tags are set in different threads for the cloned plans.\r\n\r\nSee the description of [SPARK-43157](https://issues.apache.org/jira/browse/SPARK-43157) for an example of the concurrency issue.\r\n\r\n### Does this PR introduce _any_ user-facing change?\r\nYes. It fixes a driver hanging issue the user can observe.\r\n\r\n### How was this patch tested?\r\nUnit test added and I manually verified `Dataset.explain(\"formatted\")` still had the expected output.\r\n```scala\r\nspark.range(10).cache.filter($\"id\" > 5).explain(\"formatted\")\r\n\r\n== Physical Plan ==\r\n* Filter (4)\r\n+- InMemoryTableScan (1)\r\n      +- InMemoryRelation (2)\r\n            +- * Range (3)\r\n\r\n\r\n(1) InMemoryTableScan\r\nOutput [1]: [id#0L]\r\nArguments: [id#0L], [(id#0L > 5)]\r\n\r\n(2) InMemoryRelation\r\nArguments: [id#0L], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@418b946b,StorageLevel(disk, memory, deserialized, 1 replicas),*(1) Range (0, 10, step=1, splits=16)\r\n,None), [id#0L ASC NULLS FIRST]\r\n\r\n(3) Range [codegen id : 1]\r\nOutput [1]: [id#0L]\r\nArguments: Range (0, 10, step=1, splits=Some(16))\r\n\r\n(4) Filter [codegen id : 1]\r\nInput [1]: [id#0L]\r\nCondition : (id#0L > 5)\r\n```\r\n\r\nI also verified that the `InMemory.innerChildren` is cloned when the entire plan is cloned.\r\n```scala\r\nimport org.apache.spark.sql.execution.SparkPlan\r\nimport org.apache.spark.sql.execution.columnar.InMemoryTableScanExec\r\nimport spark.implicits._\r\n\r\ndef findCacheOperator(plan: SparkPlan): Option[InMemoryTableScanExec] = {\r\n  if (plan.isInstanceOf[InMemoryTableScanExec]) {\r\n    Some(plan.asInstanceOf[InMemoryTableScanExec])\r\n  } else if (plan.children.isEmpty && plan.subqueries.isEmpty) {\r\n    None\r\n  } else {\r\n    (plan.subqueries.flatMap(p => findCacheOperator(p)) ++\r\n      plan.children.flatMap(findCacheOperator)).headOption\r\n  }\r\n}\r\n\r\nval df = spark.range(10).filter($\"id\" < 100).cache()\r\nval df1 = df.limit(1)\r\nval df2 = df.limit(1)\r\n\r\n// Get the cache operator (InMemoryTableScanExec) in each plan\r\nval plan1 = findCacheOperator(df1.queryExecution.executedPlan).get\r\nval plan2 = findCacheOperator(df2.queryExecution.executedPlan).get\r\n\r\n// Check if InMemoryTableScanExec references point to the same object\r\nprintln(plan1.eq(plan2))\r\n// returns false// Check if InMemoryRelation references point to the same object\r\n\r\nprintln(plan1.relation.eq(plan2.relation))\r\n// returns false\r\n\r\n// Check if the cached SparkPlan references point to the same object\r\nprintln(plan1.relation.innerChildren.head.eq(plan2.relation.innerChildren.head))\r\n// returns false\r\n// This shows the issue is fixed\r\n```",
  "closed_by": {
    "login": "cloud-fan",
    "id": 3182036,
    "node_id": "MDQ6VXNlcjMxODIwMzY=",
    "avatar_url": "https://avatars.githubusercontent.com/u/3182036?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/cloud-fan",
    "html_url": "https://github.com/cloud-fan",
    "followers_url": "https://api.github.com/users/cloud-fan/followers",
    "following_url": "https://api.github.com/users/cloud-fan/following{/other_user}",
    "gists_url": "https://api.github.com/users/cloud-fan/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/cloud-fan/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/cloud-fan/subscriptions",
    "organizations_url": "https://api.github.com/users/cloud-fan/orgs",
    "repos_url": "https://api.github.com/users/cloud-fan/repos",
    "events_url": "https://api.github.com/users/cloud-fan/events{/privacy}",
    "received_events_url": "https://api.github.com/users/cloud-fan/received_events",
    "type": "User",
    "site_admin": false
  },
  "reactions": {
    "url": "https://api.github.com/repos/apache/spark/issues/40812/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/apache/spark/issues/40812/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
