{
  "url": "https://api.github.com/repos/apache/spark/issues/40998",
  "repository_url": "https://api.github.com/repos/apache/spark",
  "labels_url": "https://api.github.com/repos/apache/spark/issues/40998/labels{/name}",
  "comments_url": "https://api.github.com/repos/apache/spark/issues/40998/comments",
  "events_url": "https://api.github.com/repos/apache/spark/issues/40998/events",
  "html_url": "https://github.com/apache/spark/pull/40998",
  "id": 1689312392,
  "node_id": "PR_kwDOAQXtWs5PbTal",
  "number": 40998,
  "title": "[SPARK-43323][SQL][PYTHON] Fix DataFrame.toPandas with Arrow enabled to handle exceptions properly",
  "user": {
    "login": "ueshin",
    "id": 506656,
    "node_id": "MDQ6VXNlcjUwNjY1Ng==",
    "avatar_url": "https://avatars.githubusercontent.com/u/506656?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/ueshin",
    "html_url": "https://github.com/ueshin",
    "followers_url": "https://api.github.com/users/ueshin/followers",
    "following_url": "https://api.github.com/users/ueshin/following{/other_user}",
    "gists_url": "https://api.github.com/users/ueshin/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/ueshin/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/ueshin/subscriptions",
    "organizations_url": "https://api.github.com/users/ueshin/orgs",
    "repos_url": "https://api.github.com/users/ueshin/repos",
    "events_url": "https://api.github.com/users/ueshin/events{/privacy}",
    "received_events_url": "https://api.github.com/users/ueshin/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [
    {
      "id": 1405794576,
      "node_id": "MDU6TGFiZWwxNDA1Nzk0NTc2",
      "url": "https://api.github.com/repos/apache/spark/labels/SQL",
      "name": "SQL",
      "color": "ededed",
      "default": false,
      "description": null
    },
    {
      "id": 1981527456,
      "node_id": "MDU6TGFiZWwxOTgxNTI3NDU2",
      "url": "https://api.github.com/repos/apache/spark/labels/CORE",
      "name": "CORE",
      "color": "ededed",
      "default": false,
      "description": null
    },
    {
      "id": 1982260031,
      "node_id": "MDU6TGFiZWwxOTgyMjYwMDMx",
      "url": "https://api.github.com/repos/apache/spark/labels/PYTHON",
      "name": "PYTHON",
      "color": "ededed",
      "default": false,
      "description": null
    },
    {
      "id": 4556440342,
      "node_id": "LA_kwDOAQXtWs8AAAABD5XDFg",
      "url": "https://api.github.com/repos/apache/spark/labels/CONNECT",
      "name": "CONNECT",
      "color": "ededed",
      "default": false,
      "description": null
    }
  ],
  "state": "closed",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 1,
  "created_at": "2023-04-29T01:45:46Z",
  "updated_at": "2023-05-01T23:16:59Z",
  "closed_at": "2023-05-01T23:16:59Z",
  "author_association": "MEMBER",
  "active_lock_reason": null,
  "draft": false,
  "pull_request": {
    "url": "https://api.github.com/repos/apache/spark/pulls/40998",
    "html_url": "https://github.com/apache/spark/pull/40998",
    "diff_url": "https://github.com/apache/spark/pull/40998.diff",
    "patch_url": "https://github.com/apache/spark/pull/40998.patch",
    "merged_at": null
  },
  "body": "### What changes were proposed in this pull request?\r\n\r\nFixes `DataFrame.toPandas` with Arrow enabled to handle exceptions properly.\r\n\r\n```py\r\n>>> spark.conf.set(\"spark.sql.ansi.enabled\", True)\r\n>>> spark.conf.set('spark.sql.execution.arrow.pyspark.enabled', True)\r\n>>> spark.sql(\"select 1/0\").toPandas()\r\n...\r\nTraceback (most recent call last):\r\n...\r\npyspark.errors.exceptions.captured.ArithmeticException: [DIVIDE_BY_ZERO] Division by zero. Use `try_divide` to tolerate divisor being 0 and return NULL instead. If necessary set \"spark.sql.ansi.enabled\" to \"false\" to bypass this error.\r\n== SQL(line 1, position 8) ==\r\nselect 1/0\r\n       ^^^\r\n\r\n```\r\n\r\n### Why are the changes needed?\r\n\r\nCurrently `DataFrame.toPandas` doesn't capture exceptions happened in Spark properly.\r\n\r\n```py\r\n>>> spark.conf.set(\"spark.sql.ansi.enabled\", True)\r\n>>> spark.conf.set('spark.sql.execution.arrow.pyspark.enabled', True)\r\n>>> spark.sql(\"select 1/0\").toPandas()\r\n...\r\n  An error occurred while calling o53.getResult.\r\n: org.apache.spark.SparkException: Exception thrown in awaitResult:\r\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\r\n...\r\n```\r\n\r\nbecause `jsocket_auth_server.getResult()` always wraps the thrown exceptions with `SparkException` that won't be captured.\r\n\r\nWhereas without Arrow:\r\n\r\n```py\r\n>>> spark.conf.set(\"spark.sql.ansi.enabled\", True)\r\n>>> spark.conf.set('spark.sql.execution.arrow.pyspark.enabled', False)\r\n>>> spark.sql(\"select 1/0\").toPandas()\r\nTraceback (most recent call last):\r\n...\r\npyspark.errors.exceptions.captured.ArithmeticException: [DIVIDE_BY_ZERO] Division by zero. Use `try_divide` to tolerate divisor being 0 and return NULL instead. If necessary set \"spark.sql.ansi.enabled\" to \"false\" to bypass this error.\r\n== SQL(line 1, position 8) ==\r\nselect 1/0\r\n       ^^^\r\n```\r\n\r\n### Does this PR introduce _any_ user-facing change?\r\n\r\n`DataFrame.toPandas` with Arrow enabled will show a proper exception.\r\n\r\n### How was this patch tested?\r\n\r\nAdded the related test.",
  "closed_by": {
    "login": "HyukjinKwon",
    "id": 6477701,
    "node_id": "MDQ6VXNlcjY0Nzc3MDE=",
    "avatar_url": "https://avatars.githubusercontent.com/u/6477701?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/HyukjinKwon",
    "html_url": "https://github.com/HyukjinKwon",
    "followers_url": "https://api.github.com/users/HyukjinKwon/followers",
    "following_url": "https://api.github.com/users/HyukjinKwon/following{/other_user}",
    "gists_url": "https://api.github.com/users/HyukjinKwon/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/HyukjinKwon/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/HyukjinKwon/subscriptions",
    "organizations_url": "https://api.github.com/users/HyukjinKwon/orgs",
    "repos_url": "https://api.github.com/users/HyukjinKwon/repos",
    "events_url": "https://api.github.com/users/HyukjinKwon/events{/privacy}",
    "received_events_url": "https://api.github.com/users/HyukjinKwon/received_events",
    "type": "User",
    "site_admin": false
  },
  "reactions": {
    "url": "https://api.github.com/repos/apache/spark/issues/40998/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/apache/spark/issues/40998/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
