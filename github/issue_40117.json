{
  "url": "https://api.github.com/repos/apache/spark/issues/40117",
  "repository_url": "https://api.github.com/repos/apache/spark",
  "labels_url": "https://api.github.com/repos/apache/spark/issues/40117/labels{/name}",
  "comments_url": "https://api.github.com/repos/apache/spark/issues/40117/comments",
  "events_url": "https://api.github.com/repos/apache/spark/issues/40117/events",
  "html_url": "https://github.com/apache/spark/pull/40117",
  "id": 1594540195,
  "node_id": "PR_kwDOAQXtWs5KfA_3",
  "number": 40117,
  "title": "[SPARK-42427][SQL][TESTS][FOLLOW-UP] Disable ANSI for several conv test cases in MathFunctionsSuite",
  "user": {
    "login": "HyukjinKwon",
    "id": 6477701,
    "node_id": "MDQ6VXNlcjY0Nzc3MDE=",
    "avatar_url": "https://avatars.githubusercontent.com/u/6477701?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/HyukjinKwon",
    "html_url": "https://github.com/HyukjinKwon",
    "followers_url": "https://api.github.com/users/HyukjinKwon/followers",
    "following_url": "https://api.github.com/users/HyukjinKwon/following{/other_user}",
    "gists_url": "https://api.github.com/users/HyukjinKwon/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/HyukjinKwon/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/HyukjinKwon/subscriptions",
    "organizations_url": "https://api.github.com/users/HyukjinKwon/orgs",
    "repos_url": "https://api.github.com/users/HyukjinKwon/repos",
    "events_url": "https://api.github.com/users/HyukjinKwon/events{/privacy}",
    "received_events_url": "https://api.github.com/users/HyukjinKwon/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [
    {
      "id": 1405794576,
      "node_id": "MDU6TGFiZWwxNDA1Nzk0NTc2",
      "url": "https://api.github.com/repos/apache/spark/labels/SQL",
      "name": "SQL",
      "color": "ededed",
      "default": false,
      "description": null
    }
  ],
  "state": "closed",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 2,
  "created_at": "2023-02-22T06:33:53Z",
  "updated_at": "2023-02-22T11:38:14Z",
  "closed_at": "2023-02-22T11:38:14Z",
  "author_association": "MEMBER",
  "active_lock_reason": null,
  "draft": false,
  "pull_request": {
    "url": "https://api.github.com/repos/apache/spark/pulls/40117",
    "html_url": "https://github.com/apache/spark/pull/40117",
    "diff_url": "https://github.com/apache/spark/pull/40117.diff",
    "patch_url": "https://github.com/apache/spark/pull/40117.patch",
    "merged_at": null
  },
  "body": "### What changes were proposed in this pull request?\r\n\r\nThis PR proposes to disable ANSI for several conv test cases in `MathFunctionsSuite`. They are intentionally testing the behaviours when ANSI is disabled. Exception cases are already handled in https://github.com/apache/spark/commit/cb463fb40e8f663b7e3019c8d8560a3490c241d0 I believe.\r\n\r\n### Why are the changes needed?\r\n\r\nTo make the ANSI tests pass. It currently fails (https://github.com/apache/spark/actions/runs/4228390267/jobs/7343793692):\r\n\r\n```\r\n2023-02-21T03:03:20.3799795Z \u001B[0m[\u001B[0m\u001B[0minfo\u001B[0m] \u001B[0m\u001B[0m\u001B[32m- SPARK-33428 conv function should trim input string (177 milliseconds)\u001B[0m\u001B[0m\r\n2023-02-21T03:03:20.4252604Z 03:03:20.424 ERROR org.apache.spark.executor.Executor: Exception in task 0.0 in stage 138.0 (TID 256)\r\n2023-02-21T03:03:20.4253602Z org.apache.spark.SparkArithmeticException: [ARITHMETIC_OVERFLOW] Overflow in function conv(). If necessary set \"spark.sql.ansi.enabled\" to \"false\" to bypass this error.\r\n2023-02-21T03:03:20.4254440Z \tat org.apache.spark.sql.errors.QueryExecutionErrors$.arithmeticOverflowError(QueryExecutionErrors.scala:643)\r\n2023-02-21T03:03:20.4255265Z \tat org.apache.spark.sql.errors.QueryExecutionErrors$.overflowInConvError(QueryExecutionErrors.scala:315)\r\n2023-02-21T03:03:20.4256001Z \tat org.apache.spark.sql.catalyst.util.NumberConverter$.encode(NumberConverter.scala:68)\r\n2023-02-21T03:03:20.4256888Z \tat org.apache.spark.sql.catalyst.util.NumberConverter$.convert(NumberConverter.scala:158)\r\n2023-02-21T03:03:20.4257450Z \tat org.apache.spark.sql.catalyst.util.NumberConverter.convert(NumberConverter.scala)\r\n2023-02-21T03:03:20.4258084Z \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(generated.java:38)\r\n2023-02-21T03:03:20.4258720Z \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n2023-02-21T03:03:20.4259293Z \tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\r\n2023-02-21T03:03:20.4259769Z \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n2023-02-21T03:03:20.4260157Z \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n2023-02-21T03:03:20.4260535Z \tat org.apache.spark.util.Iterators$.size(Iterators.scala:29)\r\n2023-02-21T03:03:20.4260918Z \tat org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1944)\r\n2023-02-21T03:03:20.4261283Z \tat org.apache.spark.rdd.RDD.$anonfun$count$1(RDD.scala:1266)\r\n2023-02-21T03:03:20.4261649Z \tat org.apache.spark.rdd.RDD.$anonfun$count$1$adapted(RDD.scala:1266)\r\n2023-02-21T03:03:20.4262050Z \tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2303)\r\n2023-02-21T03:03:20.4262726Z \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\r\n2023-02-21T03:03:20.4263206Z \tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n2023-02-21T03:03:20.4263628Z \tat org.apache.spark.scheduler.Task.run(Task.scala:139)\r\n2023-02-21T03:03:20.4264227Z \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\r\n2023-02-21T03:03:20.4265048Z \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1520)\r\n2023-02-21T03:03:20.4266209Z \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\r\n2023-02-21T03:03:20.4266805Z \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n2023-02-21T03:03:20.4267369Z \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n2023-02-21T03:03:20.4267799Z \tat java.lang.Thread.run(Thread.java:750)\r\n```\r\n\r\n### Does this PR introduce _any_ user-facing change?\r\n\r\nNo, test-only.\r\n\r\n### How was this patch tested?\r\n\r\nFixed unittests.",
  "closed_by": {
    "login": "HyukjinKwon",
    "id": 6477701,
    "node_id": "MDQ6VXNlcjY0Nzc3MDE=",
    "avatar_url": "https://avatars.githubusercontent.com/u/6477701?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/HyukjinKwon",
    "html_url": "https://github.com/HyukjinKwon",
    "followers_url": "https://api.github.com/users/HyukjinKwon/followers",
    "following_url": "https://api.github.com/users/HyukjinKwon/following{/other_user}",
    "gists_url": "https://api.github.com/users/HyukjinKwon/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/HyukjinKwon/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/HyukjinKwon/subscriptions",
    "organizations_url": "https://api.github.com/users/HyukjinKwon/orgs",
    "repos_url": "https://api.github.com/users/HyukjinKwon/repos",
    "events_url": "https://api.github.com/users/HyukjinKwon/events{/privacy}",
    "received_events_url": "https://api.github.com/users/HyukjinKwon/received_events",
    "type": "User",
    "site_admin": false
  },
  "reactions": {
    "url": "https://api.github.com/repos/apache/spark/issues/40117/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/apache/spark/issues/40117/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
