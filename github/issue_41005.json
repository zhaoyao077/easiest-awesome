{
  "url": "https://api.github.com/repos/apache/spark/issues/41005",
  "repository_url": "https://api.github.com/repos/apache/spark",
  "labels_url": "https://api.github.com/repos/apache/spark/issues/41005/labels{/name}",
  "comments_url": "https://api.github.com/repos/apache/spark/issues/41005/comments",
  "events_url": "https://api.github.com/repos/apache/spark/issues/41005/events",
  "html_url": "https://github.com/apache/spark/pull/41005",
  "id": 1691174430,
  "node_id": "PR_kwDOAQXtWs5PhUA3",
  "number": 41005,
  "title": "[SPARK-43331][CONNECT] Add Spark Connect SparkSession.interruptAll ",
  "user": {
    "login": "juliuszsompolski",
    "id": 25019163,
    "node_id": "MDQ6VXNlcjI1MDE5MTYz",
    "avatar_url": "https://avatars.githubusercontent.com/u/25019163?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/juliuszsompolski",
    "html_url": "https://github.com/juliuszsompolski",
    "followers_url": "https://api.github.com/users/juliuszsompolski/followers",
    "following_url": "https://api.github.com/users/juliuszsompolski/following{/other_user}",
    "gists_url": "https://api.github.com/users/juliuszsompolski/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/juliuszsompolski/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/juliuszsompolski/subscriptions",
    "organizations_url": "https://api.github.com/users/juliuszsompolski/orgs",
    "repos_url": "https://api.github.com/users/juliuszsompolski/repos",
    "events_url": "https://api.github.com/users/juliuszsompolski/events{/privacy}",
    "received_events_url": "https://api.github.com/users/juliuszsompolski/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [
    {
      "id": 1405794576,
      "node_id": "MDU6TGFiZWwxNDA1Nzk0NTc2",
      "url": "https://api.github.com/repos/apache/spark/labels/SQL",
      "name": "SQL",
      "color": "ededed",
      "default": false,
      "description": null
    },
    {
      "id": 1981527456,
      "node_id": "MDU6TGFiZWwxOTgxNTI3NDU2",
      "url": "https://api.github.com/repos/apache/spark/labels/CORE",
      "name": "CORE",
      "color": "ededed",
      "default": false,
      "description": null
    },
    {
      "id": 1982260031,
      "node_id": "MDU6TGFiZWwxOTgyMjYwMDMx",
      "url": "https://api.github.com/repos/apache/spark/labels/PYTHON",
      "name": "PYTHON",
      "color": "ededed",
      "default": false,
      "description": null
    },
    {
      "id": 4556440342,
      "node_id": "LA_kwDOAQXtWs8AAAABD5XDFg",
      "url": "https://api.github.com/repos/apache/spark/labels/CONNECT",
      "name": "CONNECT",
      "color": "ededed",
      "default": false,
      "description": null
    }
  ],
  "state": "closed",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 4,
  "created_at": "2023-05-01T18:41:40Z",
  "updated_at": "2023-05-22T19:24:56Z",
  "closed_at": "2023-05-03T15:48:25Z",
  "author_association": "CONTRIBUTOR",
  "active_lock_reason": null,
  "draft": false,
  "pull_request": {
    "url": "https://api.github.com/repos/apache/spark/pulls/41005",
    "html_url": "https://github.com/apache/spark/pull/41005",
    "diff_url": "https://github.com/apache/spark/pull/41005.diff",
    "patch_url": "https://github.com/apache/spark/pull/41005.patch",
    "merged_at": null
  },
  "body": "### What changes were proposed in this pull request?\r\n\r\nCurrently, queries that are ran using Spark Connect cannot be interrupted. Even when the RPC connection got broken, the Spark jobs on the server continue running.\r\n\r\nThis PR proposes a \r\n```\r\nrpc Interrupt(InterruptRequest) returns (InterruptResponse) {}\r\n```\r\nserver RPC API, that can be called from the client as `SparkSession.interruptAll()` to interrupt all actively running Spark Jobs from ExecutePlan executions. In most user scenarios, SparkSession is not used for multiple executions concurrently, but is used sequentially, so `interruptAll()` should serve a big chunk of user needs. It can also be used to clean up.\r\n\r\nTo keep track of executions, we introduce `ExecutionHolder` to hold the execution state, and make `SessionHolder` keep track of the executions currently running in the session. In this first PR, the interrupt only interrupts running Spark Jobs. As such, it is to a degree best effort, because it will not interrupt commands that don't run Spark Jobs, or it will not interrupt anything if a Spark Job is not running when it the interrupt is received by the server, and  the command will continue running and may continue launching more Spark jobs later in that case.\r\n\r\nFuture work I plan to design and work on will involve:\r\n* Interrupting any execution. This will involve moving execution from the GRPC handler thread handling ExecutePlan to launching it in a separate thread that can be interrupted. `ExecutionHolder`\r\n* Interrupting executions selectively. This will involve exposing the operationId to the user.\r\n* (Refactor) some cleanup needed around using SessionHolder. Currently, sessionId, userId, various session data is passed around separately. SessionHolder may be passed instead, and then also be extended with more useful APIs for management of the session.\r\n\r\n### Why are the changes needed?\r\n\r\nNeed to have APIs to be able to interrupt running queries in Spark Connect.\r\n\r\n### Does this PR introduce _any_ user-facing change?\r\n\r\nYes.\r\nUsers of Spark Connect can now call `interruptAll()` on client `SparkSession` object, to send an interrupt RPC to the server, which will interrupt the running queries.\r\n\r\nIn followup PRs, this will be extended to Python client, and to work not only for interrupting Spark Jobs.\r\n\r\n### How was this patch tested?\r\n\r\nAdded E2E tests to ClientE2ETestSuite for scala connect client.\r\nAdded unit tests to test_client for python connect client.\r\n",
  "closed_by": {
    "login": "hvanhovell",
    "id": 9616802,
    "node_id": "MDQ6VXNlcjk2MTY4MDI=",
    "avatar_url": "https://avatars.githubusercontent.com/u/9616802?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/hvanhovell",
    "html_url": "https://github.com/hvanhovell",
    "followers_url": "https://api.github.com/users/hvanhovell/followers",
    "following_url": "https://api.github.com/users/hvanhovell/following{/other_user}",
    "gists_url": "https://api.github.com/users/hvanhovell/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/hvanhovell/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/hvanhovell/subscriptions",
    "organizations_url": "https://api.github.com/users/hvanhovell/orgs",
    "repos_url": "https://api.github.com/users/hvanhovell/repos",
    "events_url": "https://api.github.com/users/hvanhovell/events{/privacy}",
    "received_events_url": "https://api.github.com/users/hvanhovell/received_events",
    "type": "User",
    "site_admin": false
  },
  "reactions": {
    "url": "https://api.github.com/repos/apache/spark/issues/41005/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/apache/spark/issues/41005/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
