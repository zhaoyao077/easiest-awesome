{
  "url": "https://api.github.com/repos/apache/spark/issues/40896",
  "repository_url": "https://api.github.com/repos/apache/spark",
  "labels_url": "https://api.github.com/repos/apache/spark/issues/40896/labels{/name}",
  "comments_url": "https://api.github.com/repos/apache/spark/issues/40896/comments",
  "events_url": "https://api.github.com/repos/apache/spark/issues/40896/events",
  "html_url": "https://github.com/apache/spark/pull/40896",
  "id": 1678020434,
  "node_id": "PR_kwDOAQXtWs5O1f3X",
  "number": 40896,
  "title": "[SPARK-43229][ML][PYTHON][CONNECT] Introduce Barrier Python UDF",
  "user": {
    "login": "zhengruifeng",
    "id": 7322292,
    "node_id": "MDQ6VXNlcjczMjIyOTI=",
    "avatar_url": "https://avatars.githubusercontent.com/u/7322292?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/zhengruifeng",
    "html_url": "https://github.com/zhengruifeng",
    "followers_url": "https://api.github.com/users/zhengruifeng/followers",
    "following_url": "https://api.github.com/users/zhengruifeng/following{/other_user}",
    "gists_url": "https://api.github.com/users/zhengruifeng/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/zhengruifeng/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/zhengruifeng/subscriptions",
    "organizations_url": "https://api.github.com/users/zhengruifeng/orgs",
    "repos_url": "https://api.github.com/users/zhengruifeng/repos",
    "events_url": "https://api.github.com/users/zhengruifeng/events{/privacy}",
    "received_events_url": "https://api.github.com/users/zhengruifeng/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [
    {
      "id": 1405794576,
      "node_id": "MDU6TGFiZWwxNDA1Nzk0NTc2",
      "url": "https://api.github.com/repos/apache/spark/labels/SQL",
      "name": "SQL",
      "color": "ededed",
      "default": false,
      "description": null
    },
    {
      "id": 1405801475,
      "node_id": "MDU6TGFiZWwxNDA1ODAxNDc1",
      "url": "https://api.github.com/repos/apache/spark/labels/ML",
      "name": "ML",
      "color": "ededed",
      "default": false,
      "description": null
    },
    {
      "id": 1981527456,
      "node_id": "MDU6TGFiZWwxOTgxNTI3NDU2",
      "url": "https://api.github.com/repos/apache/spark/labels/CORE",
      "name": "CORE",
      "color": "ededed",
      "default": false,
      "description": null
    },
    {
      "id": 1982260031,
      "node_id": "MDU6TGFiZWwxOTgyMjYwMDMx",
      "url": "https://api.github.com/repos/apache/spark/labels/PYTHON",
      "name": "PYTHON",
      "color": "ededed",
      "default": false,
      "description": null
    },
    {
      "id": 4556440342,
      "node_id": "LA_kwDOAQXtWs8AAAABD5XDFg",
      "url": "https://api.github.com/repos/apache/spark/labels/CONNECT",
      "name": "CONNECT",
      "color": "ededed",
      "default": false,
      "description": null
    }
  ],
  "state": "closed",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 12,
  "created_at": "2023-04-21T07:37:30Z",
  "updated_at": "2023-05-22T11:07:11Z",
  "closed_at": "2023-05-22T11:07:07Z",
  "author_association": "CONTRIBUTOR",
  "active_lock_reason": null,
  "draft": false,
  "pull_request": {
    "url": "https://api.github.com/repos/apache/spark/pulls/40896",
    "html_url": "https://github.com/apache/spark/pull/40896",
    "diff_url": "https://github.com/apache/spark/pull/40896.diff",
    "patch_url": "https://github.com/apache/spark/pull/40896.patch",
    "merged_at": null
  },
  "body": "### What changes were proposed in this pull request?\r\n\r\nThis PR reverts changes from [SPARK-42896](https://issues.apache.org/jira/browse/SPARK-42896) and [SPARK-42929](https://issues.apache.org/jira/browse/SPARK-42929) which made `mapInPandas` and `mapInArrow` support barrier mode execution via adding a `is_barrier` parameter.\r\n\r\nInstead, this PR add `is_barrier` as a optional function attribute, so that the barrier python UDF can be supported in physical operators other than `MapInBatchExec`.\r\n\r\nRight now I want to narrow its usage scope because it is only used in ML:\r\n\r\n- only supported in Pandas UDF;\r\n- only supported in `MapInPandas` and `MapInArrow`;\r\n- can not be registered;\r\n\r\nThis PR will not add a user-facing API or Parameter or Annotation, instead only a _private_ function attribute will be added, that is because:\r\n\r\n- Right now it is only needed to integrate external ML training frameworks like PyTorch and XGBoost, which just run `collect` after the UDF execution to obtain the model coefficients;\r\n- The limitation of existing barrier mode: many RDD operations are not supported, see [1](https://github.com/apache/spark/blob/1a6b1770c85f37982b15d261abf9cc6e4be740f4/core/src/main/scala/org/apache/spark/scheduler/DAGScheduler.scala#L474-L488) and [2](https://github.com/apache/spark/blob/485145326a9c97ede260b0e267ee116f182cfd56/core/src/main/scala/org/apache/spark/scheduler/BarrierJobAllocationFailed.scala#L42-L65) . And it is non-trivial to make `RDDBarrier` fully compatible with `RDD`.\r\n \r\nA simple example to illustrate this problem:\r\n```\r\nIn [1]: df = spark.createDataFrame([(1, 21), (2, 30)], (\"id\", \"age\"))\r\n\r\nIn [2]: def filter_func(iterator):\r\n   ...:     for pdf in iterator:\r\n   ...:         yield pdf[pdf.id == 1]\r\n   ...: \r\n\r\nIn [3]: df.mapInPandas(filter_func, df.schema).explain()\r\n== Physical Plan ==\r\nMapInPandas filter_func(id#0L, age#1L)#4, [id#5L, age#6L], false\r\n+- *(1) Scan ExistingRDD[id#0L,age#1L]\r\n\r\n\r\n\r\nIn [4]: df.mapInPandas(filter_func, df.schema).show()\r\n+---+---+                                                                       \r\n| id|age|\r\n+---+---+\r\n|  1| 21|\r\n+---+---+\r\n\r\n\r\nIn [5]: df.mapInPandas(filter_func, df.schema, barrier=True).explain()\r\n== Physical Plan ==\r\nMapInPandas filter_func(id#0L, age#1L)#23, [id#24L, age#25L], true\r\n+- *(1) Scan ExistingRDD[id#0L,age#1L]\r\n\r\n\r\n\r\nIn [6]: df.mapInPandas(filter_func, df.schema, barrier=True).show()\r\n23/04/26 15:39:57 WARN DAGScheduler: Creating new stage failed due to exception - job: 3\r\norg.apache.spark.scheduler.BarrierJobUnsupportedRDDChainException: [SPARK-24820][SPARK-24821]: Barrier execution mode does not allow the following pattern of RDD chain within a barrier stage:\r\n1. Ancestor RDDs that have different number of partitions from the resulting RDD (e.g. union()/coalesce()/first()/take()/PartitionPruningRDD). A workaround for first()/take() can be barrierRdd.collect().head (scala) or barrierRdd.collect()[0] (python).\r\n2. An RDD that depends on multiple barrier RDDs (e.g. barrierRdd1.zip(barrierRdd2)).\r\n        at org.apache.spark.errors.SparkCoreErrors$.barrierStageWithRDDChainPatternError(SparkCoreErrors.scala:225)\r\n        at org.apache.spark.scheduler.DAGScheduler.checkBarrierStageWithRDDChainPattern(DAGScheduler.scala:486)\r\n        at org.apache.spark.scheduler.DAGScheduler.createResultStage(DAGScheduler.scala:635)\r\n        at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1254)\r\n        at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2961)\r\n        at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2953)\r\n        at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2942)\r\n        at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n```\r\n\r\n### Why are the changes needed?\r\nTo make barrier python UDF able to be supported in other dataframe operator in the future, in the mean time, do not expose it to the end users\r\n\r\n\r\n### Does this PR introduce _any_ user-facing change?\r\nNo\r\n\r\n\r\n### How was this patch tested?\r\nexisting UTs",
  "closed_by": {
    "login": "zhengruifeng",
    "id": 7322292,
    "node_id": "MDQ6VXNlcjczMjIyOTI=",
    "avatar_url": "https://avatars.githubusercontent.com/u/7322292?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/zhengruifeng",
    "html_url": "https://github.com/zhengruifeng",
    "followers_url": "https://api.github.com/users/zhengruifeng/followers",
    "following_url": "https://api.github.com/users/zhengruifeng/following{/other_user}",
    "gists_url": "https://api.github.com/users/zhengruifeng/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/zhengruifeng/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/zhengruifeng/subscriptions",
    "organizations_url": "https://api.github.com/users/zhengruifeng/orgs",
    "repos_url": "https://api.github.com/users/zhengruifeng/repos",
    "events_url": "https://api.github.com/users/zhengruifeng/events{/privacy}",
    "received_events_url": "https://api.github.com/users/zhengruifeng/received_events",
    "type": "User",
    "site_admin": false
  },
  "reactions": {
    "url": "https://api.github.com/repos/apache/spark/issues/40896/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/apache/spark/issues/40896/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
