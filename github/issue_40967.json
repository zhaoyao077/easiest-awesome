{
  "url": "https://api.github.com/repos/apache/spark/issues/40967",
  "repository_url": "https://api.github.com/repos/apache/spark",
  "labels_url": "https://api.github.com/repos/apache/spark/issues/40967/labels{/name}",
  "comments_url": "https://api.github.com/repos/apache/spark/issues/40967/comments",
  "events_url": "https://api.github.com/repos/apache/spark/issues/40967/events",
  "html_url": "https://github.com/apache/spark/pull/40967",
  "id": 1685710111,
  "node_id": "PR_kwDOAQXtWs5PPJx6",
  "number": 40967,
  "title": "[SPARK-43298][PYTHON][ML] predict_batch_udf with scalar input fails with batch size of one",
  "user": {
    "login": "leewyang",
    "id": 3676078,
    "node_id": "MDQ6VXNlcjM2NzYwNzg=",
    "avatar_url": "https://avatars.githubusercontent.com/u/3676078?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/leewyang",
    "html_url": "https://github.com/leewyang",
    "followers_url": "https://api.github.com/users/leewyang/followers",
    "following_url": "https://api.github.com/users/leewyang/following{/other_user}",
    "gists_url": "https://api.github.com/users/leewyang/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/leewyang/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/leewyang/subscriptions",
    "organizations_url": "https://api.github.com/users/leewyang/orgs",
    "repos_url": "https://api.github.com/users/leewyang/repos",
    "events_url": "https://api.github.com/users/leewyang/events{/privacy}",
    "received_events_url": "https://api.github.com/users/leewyang/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [
    {
      "id": 1405801475,
      "node_id": "MDU6TGFiZWwxNDA1ODAxNDc1",
      "url": "https://api.github.com/repos/apache/spark/labels/ML",
      "name": "ML",
      "color": "ededed",
      "default": false,
      "description": null
    },
    {
      "id": 1981527456,
      "node_id": "MDU6TGFiZWwxOTgxNTI3NDU2",
      "url": "https://api.github.com/repos/apache/spark/labels/CORE",
      "name": "CORE",
      "color": "ededed",
      "default": false,
      "description": null
    },
    {
      "id": 1982260031,
      "node_id": "MDU6TGFiZWwxOTgyMjYwMDMx",
      "url": "https://api.github.com/repos/apache/spark/labels/PYTHON",
      "name": "PYTHON",
      "color": "ededed",
      "default": false,
      "description": null
    }
  ],
  "state": "closed",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 7,
  "created_at": "2023-04-26T20:54:22Z",
  "updated_at": "2023-04-28T15:43:49Z",
  "closed_at": "2023-04-28T00:37:52Z",
  "author_association": "CONTRIBUTOR",
  "active_lock_reason": null,
  "draft": false,
  "pull_request": {
    "url": "https://api.github.com/repos/apache/spark/pulls/40967",
    "html_url": "https://github.com/apache/spark/pull/40967",
    "diff_url": "https://github.com/apache/spark/pull/40967.diff",
    "patch_url": "https://github.com/apache/spark/pull/40967.patch",
    "merged_at": null
  },
  "body": "### What changes were proposed in this pull request?\r\n\r\nThis is a followup to #39817 to handle another error condition when the input batch is a single scalar value (where the previous fix focused on a single scalar value output).\r\n\r\n### Why are the changes needed?\r\nUsing `predict_batch_udf` fails when the input batch size is one.\r\n```\r\nimport numpy as np\r\nfrom pyspark.ml.functions import predict_batch_udf\r\nfrom pyspark.sql.types import DoubleType\r\n\r\ndf = spark.createDataFrame([[1.0],[2.0]], schema=[\"a\"])\r\n\r\ndef make_predict_fn():\r\n    def predict(inputs):\r\n        return inputs\r\n\r\n    return predict\r\n\r\nidentity = predict_batch_udf(make_predict_fn, return_type=DoubleType(), batch_size=1)\r\npreds = df.withColumn(\"preds\", identity(\"a\")).show()\r\n```\r\nfails with:\r\n```\r\n  File \"/.../spark/python/pyspark/worker.py\", line 869, in main\r\n    process()\r\n  File \"/.../spark/python/pyspark/worker.py\", line 861, in process\r\n    serializer.dump_stream(out_iter, outfile)\r\n  File \"/.../spark/python/pyspark/sql/pandas/serializers.py\", line 354, in dump_stream\r\n    return ArrowStreamSerializer.dump_stream(self, init_stream_yield_batches(), stream)\r\n  File \"/.../spark/python/pyspark/sql/pandas/serializers.py\", line 86, in dump_stream\r\n    for batch in iterator:\r\n  File \"/.../spark/python/pyspark/sql/pandas/serializers.py\", line 347, in init_stream_yield_batches\r\n    for series in iterator:\r\n  File \"/.../spark/python/pyspark/worker.py\", line 555, in func\r\n    for result_batch, result_type in result_iter:\r\n  File \"/.../spark/python/pyspark/ml/functions.py\", line 818, in predict\r\n    yield _validate_and_transform_prediction_result(\r\n  File \"/.../spark/python/pyspark/ml/functions.py\", line 339, in _validate_and_transform_prediction_result\r\n    if len(preds_array) != num_input_rows:\r\nTypeError: len() of unsized object\r\n```\r\n\r\nAfter the fix:\r\n```\r\n+---+-----+\r\n|  a|preds|\r\n+---+-----+\r\n|1.0|  1.0|\r\n|2.0|  2.0|\r\n+---+-----+\r\n```\r\n\r\n### Does this PR introduce _any_ user-facing change?\r\nThis fixes a bug in the feature that was released in Spark 3.4.0.\r\n\r\n### How was this patch tested?\r\nUnit test was added.\r\n",
  "closed_by": {
    "login": "zhengruifeng",
    "id": 7322292,
    "node_id": "MDQ6VXNlcjczMjIyOTI=",
    "avatar_url": "https://avatars.githubusercontent.com/u/7322292?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/zhengruifeng",
    "html_url": "https://github.com/zhengruifeng",
    "followers_url": "https://api.github.com/users/zhengruifeng/followers",
    "following_url": "https://api.github.com/users/zhengruifeng/following{/other_user}",
    "gists_url": "https://api.github.com/users/zhengruifeng/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/zhengruifeng/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/zhengruifeng/subscriptions",
    "organizations_url": "https://api.github.com/users/zhengruifeng/orgs",
    "repos_url": "https://api.github.com/users/zhengruifeng/repos",
    "events_url": "https://api.github.com/users/zhengruifeng/events{/privacy}",
    "received_events_url": "https://api.github.com/users/zhengruifeng/received_events",
    "type": "User",
    "site_admin": false
  },
  "reactions": {
    "url": "https://api.github.com/repos/apache/spark/issues/40967/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/apache/spark/issues/40967/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
