[
  {
    "url": "https://api.github.com/repos/apache/spark/issues/comments/1434578211",
    "html_url": "https://github.com/apache/spark/pull/40063#issuecomment-1434578211",
    "issue_url": "https://api.github.com/repos/apache/spark/issues/40063",
    "id": 1434578211,
    "node_id": "IC_kwDOAQXtWs5Vge0j",
    "user": {
      "login": "zhengruifeng",
      "id": 7322292,
      "node_id": "MDQ6VXNlcjczMjIyOTI=",
      "avatar_url": "https://avatars.githubusercontent.com/u/7322292?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/zhengruifeng",
      "html_url": "https://github.com/zhengruifeng",
      "followers_url": "https://api.github.com/users/zhengruifeng/followers",
      "following_url": "https://api.github.com/users/zhengruifeng/following{/other_user}",
      "gists_url": "https://api.github.com/users/zhengruifeng/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/zhengruifeng/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/zhengruifeng/subscriptions",
      "organizations_url": "https://api.github.com/users/zhengruifeng/orgs",
      "repos_url": "https://api.github.com/users/zhengruifeng/repos",
      "events_url": "https://api.github.com/users/zhengruifeng/events{/privacy}",
      "received_events_url": "https://api.github.com/users/zhengruifeng/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2023-02-17T12:32:50Z",
    "updated_at": "2023-02-17T12:32:50Z",
    "author_association": "CONTRIBUTOR",
    "body": "It seems more complicated than I thought, I think we can simplify it in this way\r\n\r\nIn client:\r\n```\r\n    def sql(self, sqlQuery: str, args: Optional[Dict[str, str]] = None) -> \"DataFrame\":\r\n        df = DataFrame.withPlan(SQL(sqlQuery, args), self)\r\n        print(df.schema)   <- eagerly analyze the plan\r\n        return df\r\n```\r\n\r\nIn connect planner:\r\n```\r\n  private def transformSql(sql: proto.SQL): LogicalPlan = {\r\n    // scalastyle:off println\r\n    println(s\"invoke transformSql $sql\")\r\n    session\r\n      .sql(sql.getQuery, sql.getArgsMap.asScala.toMap)    <- directly invoke the spark session api\r\n      .logicalPlan\r\n  }\r\n```\r\n\r\n\r\nbin/pyspark --remote \"local[*]\"\r\n```\r\n>>> spark.sql(\"set spark.sql.adaptive.enabled=false\")\r\ninvoke transformSql query: \"set spark.sql.adaptive.enabled=false\"\r\n\r\nStructType([StructField('key', StringType(), False), StructField('value', StringType(), False)])\r\nDataFrame[key: string, value: string]\r\n```",
    "reactions": {
      "url": "https://api.github.com/repos/apache/spark/issues/comments/1434578211/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  }
]
